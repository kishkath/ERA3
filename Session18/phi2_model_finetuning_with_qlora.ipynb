{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:31:26.416411Z",
     "iopub.status.busy": "2025-03-12T06:31:26.416138Z",
     "iopub.status.idle": "2025-03-12T06:31:45.387036Z",
     "shell.execute_reply": "2025-03-12T06:31:45.386097Z",
     "shell.execute_reply.started": "2025-03-12T06:31:26.416390Z"
    },
    "id": "ErJ7_4ops5bl",
    "outputId": "409b6670-87a6-4a56-c298-3ad341811284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install and import the necessary libraries\n",
    "!pip install torch\n",
    "!pip install -q -U accelerate peft bitsandbytes transformers trl einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T06:31:45.388394Z",
     "iopub.status.busy": "2025-03-12T06:31:45.388138Z",
     "iopub.status.idle": "2025-03-12T06:31:47.152873Z",
     "shell.execute_reply": "2025-03-12T06:31:47.152105Z",
     "shell.execute_reply.started": "2025-03-12T06:31:45.388361Z"
    },
    "id": "IGkUjRaVtD9U"
   },
   "outputs": [],
   "source": [
    "### Load dataset (OpenAssistant/oasst1)\n",
    "from datasets import load_dataset\n",
    "\n",
    "def get_dataset():\n",
    "  dataset_loaded = load_dataset(\"OpenAssistant/oasst1\")\n",
    "  train_dataset = dataset_loaded[\"train\"].to_pandas()\n",
    "  val_dataset = dataset_loaded[\"validation\"].to_pandas()\n",
    "  return dataset_loaded, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T06:31:47.155031Z",
     "iopub.status.busy": "2025-03-12T06:31:47.154569Z",
     "iopub.status.idle": "2025-03-12T06:31:47.158361Z",
     "shell.execute_reply": "2025-03-12T06:31:47.157544Z",
     "shell.execute_reply.started": "2025-03-12T06:31:47.155008Z"
    },
    "id": "8TKYfMBZunlr"
   },
   "outputs": [],
   "source": [
    "# # paper: https://paperswithcode.com/dataset/oasst1\n",
    "\n",
    "# def prep_data(df):\n",
    "#     df_assistant = df[(df.role == \"assistant\") & (df[\"rank\"] == 0.0)].copy()\n",
    "#     df_prompter = df[(df.role == \"prompter\")].copy()\n",
    "#     df_prompter = df_prompter.set_index(\"message_id\")\n",
    "#     df_assistant[\"output\"] = df_assistant[\"text\"].values\n",
    "\n",
    "#     inputs = []\n",
    "#     parent_ids = []\n",
    "#     for _, row in df_assistant.iterrows():\n",
    "#         input = df_prompter.loc[row.parent_id]\n",
    "#         inputs.append(input.text)\n",
    "#         parent_ids.append(input.parent_id)\n",
    "\n",
    "#     df_assistant[\"instruction\"] = inputs\n",
    "#     df_assistant[\"parent_id\"] = parent_ids\n",
    "\n",
    "#     df_assistant = df_assistant[df_assistant.lang == \"en\"]\n",
    "\n",
    "#     df_assistant = df_assistant[\n",
    "#         [\"instruction\", \"output\", \"message_id\", \"parent_id\"]\n",
    "#     ].rename(columns={\"message_id\": \"id\"})\n",
    "\n",
    "#     return df_assistant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575,
     "referenced_widgets": [
      "ff7ae907159d46e28a1d4599c566e100",
      "36ae49321402495ca36513b780082001",
      "aa1da3ad783945ae9d51f3b802bf788c",
      "3726f9f10766400480d82e665171eb6c",
      "b2ec98cfc9fd4ec3a7a57363c4df72c7",
      "085a632458584226be01569f7f6e8686",
      "f366978fcc04432193d0a80ba42aa674",
      "412eee8d970747249defd91e379d51bc",
      "0461549889f34e4e8c352077d778f284",
      "b26288e06e8349dfa35350c68b987032",
      "cd160d22c6f94879a3d95b510c7cf72b",
      "ce772c6a57514178acb7acf8c76fc3d0",
      "4b68e6f0e2c24e80bb17636f230c9a2f",
      "932c979a6da342e6b63fa6965f21dae5",
      "58aa66cb1c1f4de9a5ffb3543bab5f25",
      "233652f2e5914b44a7f46443cb1b521c",
      "d6fee23fde3b47688819575ae08b9c32",
      "284149d228c24fb1816ce8395dcde1dd",
      "ceefbb587d0d406598755e0c2d4401d0",
      "41c32b49f7644e60825e955bf0f4d467",
      "aa612b750bcb4813bcfe3a41775947f9",
      "b2cd461e6b004a1d82633458b40af647",
      "1e5460d428224cb79135e28200b33d8b",
      "8bba843fc71546e9b4b54d7cee83d89b",
      "9abcf50c421f4d8a8111f1ab6a7f938d",
      "b73adce8be224298af321df1d9282e9e",
      "6a471647c7b04f57bb192f24eb720512",
      "e20a5f0d465941f49924f518d0eac2e0",
      "d7fc5c9d52e1467eb4834a17c6183ae6",
      "9206a555be614ac2a34c942fdc7f4664",
      "e0b989098bf04afeb4b7f1fb78e1571d",
      "fd8506396fe7403e8bc99c8d1db839dc",
      "530788cf8f77412aa48706ca24a82e46",
      "2d3a743ba71d40ba8d1b64ad4229ebfb",
      "793a83be0f174c2695cc417edfd48c66",
      "c23b332bcb4343deb6ce6e860384c3f4",
      "a8ad9ff98afd4a14baf0d7395ee794b2",
      "11cb86da98794d84897c978d8d5220d7",
      "b4733dfdbd5246ef802ff56552c23dc8",
      "9766ddc8906f41baa815d4e062b078c2",
      "e5bf7c3f4c11427baa24cfeda0cef564",
      "7329851a284d4f01affcc30d639e089e",
      "38c306a732a8418eb57292318e52e73a",
      "2f6602d9b81a44ae9264b14a0400f38f",
      "5d86f2ec83c342cd811eaaa383b1577c",
      "fa7f4befdb524122b45e439453c41cb0",
      "86c245f99da9414e809bd1ac5888eb15",
      "3a3dc5bba816416fb647ce94f607d66d",
      "a2fa8ebffe5d46d99bbff96c160a8924",
      "0adb8bd2215e4ab3829a62a740e67b1d",
      "7db8346b74054eb7b89465a853e9435e",
      "c6137db9572b45ad83053c0507adb3f6",
      "b8a45e86ae3c40218b0cec6010958a9f",
      "5cfecdef1a4240f0806cccb54c17ad7d",
      "f72ddd43f3f74df09cc6fd860daa2a03",
      "8ec874a0f6c8424386443f7e5604bbe5",
      "2a146a1256da4ea4868372947aaada79",
      "b7ff28ee0ef643f689ef572b438116d6",
      "5b980e2d76be4e22a9f7f6b53df1371b",
      "11076ae9ee7847fe942a32cff98aa084",
      "6317416fc4774c1f937c30546a5bb0ed",
      "60c0958f4947430aaf4255136fcc9216",
      "8c325a5d167947a69dfa09525fc924b4",
      "95139e4c9cc54727ab4ca066f373e9ff",
      "ec0350b7ebda4bde86f4d0ccb01d8f9e",
      "a149de6aa37649b9be9f8a49a2bb4152",
      "b675a24ae95147778fa2d8b0e0207831",
      "9007c63dcd2041ab9dc21f3423cdd72c",
      "6985842860fc431589fae3b23b8a4e74",
      "de0fac21ba7e4c6b9660a1a66a79455f",
      "04481c5080444393b7c0320cba05cd3c",
      "4c30a1c9724d4ad3adbe011b357da6af",
      "12d868d148984fc99a5e9001e078ff35",
      "691c1bc459044f95bc99b877cb06d899",
      "f9bcc8be1ab3475e8b1691481367e985",
      "8f1de2d7e3aa410280c5c72e9a841f9a",
      "f5e8a04cf0da4ca9894ef6f2bdc69fb1",
      "2007e96e5eee4e53addd88d4dadd14d7",
      "b682ef2c9b0a4e62994bfeaddcfc987a",
      "ec315ab81f2d4542bd5eb3eb4f082157",
      "926c6ffd8b09413291dc1ce278982f3d",
      "420e0dbc652349ef91f13b4ce71824be",
      "d9a122b7ff8644c3b71b5dd465916b46",
      "e39c56f88fae4143a9ff871b83c8c2bc",
      "07e61863ac02431b8bf0455fdb77f095",
      "cc1f481ee161422c825b948673f57dcb",
      "2ec7f1e0e8ec41c5869402d082e9f593",
      "b5917712ab7148b781ad0c4ba0eac464",
      "0a2f575bd2bf4786b8188039dd3b06ad",
      "cbd838b2d72343fbaa88f4788ddc7e49",
      "cce352387f144850bac032a3dca81469",
      "746b2133ac544ca49e754309be2a3d2e",
      "c4682645d2e4410283a622e136ad989f",
      "03d30f34e8884dbea524623f2c6da0ad",
      "9dbcdb0eeb9842cdadf1fc7e53955fa4",
      "65fe8f6b092a4db7b67673165641689d",
      "4a12f914c7b149b0b6704f494818f8af",
      "9dfe6138ecf043908e936ba1ba68b1b5",
      "faed963abab544c786f8a321a24fe8cf",
      "6177fd6a5b1f4170b5ea73a0d49af4bb",
      "cf06eb670d254e54a004cff94248787b",
      "6f7cb0ffe9a64fc2b968c64e4d004990",
      "47bd32e87c0a4654a72a83e765839083",
      "a274d141c4284b7bbb8889df34d34169",
      "bfe35ae186a04b90a8027184748f4c12",
      "2de59f6b27614f8887e6c4384c6b0f0f",
      "24c7c271e1e44ce1a5b1302378ea451a",
      "47993c49e7664654ba946859afd26a72",
      "8f88f2e2eee14459b40cd90b2fbe75da",
      "d1cb74cf35ca46138065a3733040b936",
      "2d752ab2f70e43b38d72333b4302b072",
      "08a6b467a3264115bd655d55731bcb7c",
      "5b80126ca0ee4ae6b3883e2414a2618a",
      "c0275f5e3f6e407bae94149694316030",
      "65f57968b11d4d93bdaa65ffe115c726",
      "7ab5d696cdc94e8889e764c1c0170e9b",
      "0e15ec68b2fc4e978b6afa2bf69f84b7",
      "8bc45375ce3d499dbfd444f6c0849fe8",
      "7d720ead7af04ae18259615bb63b8c04",
      "144ab929dc67452cb973f2f4d37a46aa",
      "7d91fccdb8e748d7a3eb38bc5afa6c51",
      "d4ffcf811d384572897e0c1a3aba2c2c",
      "899bdc3233b241df9cbb888471da36be",
      "ef60ae731e254892a0496528d3e7b0bc",
      "05dfcb2b3ff24664bea1a3d5c82b3e06",
      "38ed3ac2f2344d348fb755865d6f0890",
      "8a689ce4f03a48888464df06e0db24b8",
      "2bb8e52e5e194995b47714ae0eed60a9",
      "709acc81ef3a4f47be131c899a1274a6",
      "4de41386995d4428b10b2c4f551aea8c",
      "6d652db2685a4b778952e5485506a2dc",
      "a90a957b5dc540109e53bedb8875f84e",
      "629454038d4a474aa9ff5b6bc2de9400",
      "db1fcc0836ba4b4a8313b30434a45649",
      "06836b33cbfe4884a7dfa7a42b08e1ff",
      "4599bc06b41947f1b3e9436ec6c29ec8",
      "b4c36c02edca4ade92167d597a4c903e",
      "0c4132bafbba415aa5fd43ea50cf6b14",
      "b1aaccd83fc3468ba0e5d863973de4f5",
      "a781d9c3def6473781930fc339ae94b3",
      "f15255c6b6ec4872a491610af3afbe3a",
      "21aeeb9ea521410595b7f74f32d31e8f",
      "9f08d7e966c14321854d3f0b9dc34fbe"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:31:47.159879Z",
     "iopub.status.busy": "2025-03-12T06:31:47.159642Z",
     "iopub.status.idle": "2025-03-12T06:32:42.759928Z",
     "shell.execute_reply": "2025-03-12T06:32:42.759260Z",
     "shell.execute_reply.started": "2025-03-12T06:31:47.159860Z"
    },
    "id": "-BbpOis_HM1Y",
    "outputId": "9b0dc9cd-94f0-4aff-cea9-aeee1910f617"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7ae907159d46e28a1d4599c566e100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce772c6a57514178acb7acf8c76fc3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5460d428224cb79135e28200b33d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3a743ba71d40ba8d1b64ad4229ebfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d86f2ec83c342cd811eaaa383b1577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec874a0f6c8424386443f7e5604bbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b675a24ae95147778fa2d8b0e0207831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2007e96e5eee4e53addd88d4dadd14d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2f575bd2bf4786b8188039dd3b06ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6177fd6a5b1f4170b5ea73a0d49af4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d752ab2f70e43b38d72333b4302b072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ffcf811d384572897e0c1a3aba2c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629454038d4a474aa9ff5b6bc2de9400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Load Microsoft-phi2 Model\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", quantization_config=bnb_config, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", max_length=512, trust_remote_code=True)\n",
    "model.config.use_cache = False\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "# Enable gradient checkpointing for memory efficiency\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T06:32:42.761196Z",
     "iopub.status.busy": "2025-03-12T06:32:42.760714Z",
     "iopub.status.idle": "2025-03-12T06:32:42.770377Z",
     "shell.execute_reply": "2025-03-12T06:32:42.769604Z",
     "shell.execute_reply.started": "2025-03-12T06:32:42.761176Z"
    },
    "id": "TfQwI9b5R7CW"
   },
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    \"\"\"\n",
    "    Prepares data from a DataFrame by matching assistant messages to corresponding prompter instructions,\n",
    "    filtering for English examples, and merging them into a single prompt.\n",
    "    \"\"\"\n",
    "    # Filter assistant and prompter messages\n",
    "    df_assistant = df[(df.role == \"assistant\") & (df[\"rank\"] == 0.0)].copy()\n",
    "    df_prompter = df[df.role == \"prompter\"].copy()\n",
    "    df_prompter = df_prompter.set_index(\"message_id\")\n",
    "\n",
    "    # Assistant's output text\n",
    "    df_assistant[\"output\"] = df_assistant[\"text\"].values\n",
    "\n",
    "    instructions = []\n",
    "    parent_ids = []\n",
    "    # For each assistant message, get the corresponding prompter message (instruction)\n",
    "    for _, row in df_assistant.iterrows():\n",
    "        input_row = df_prompter.loc[row.parent_id]\n",
    "        instructions.append(input_row.text)\n",
    "        parent_ids.append(input_row.parent_id)\n",
    "\n",
    "    df_assistant[\"instruction\"] = instructions\n",
    "    df_assistant[\"parent_id\"] = parent_ids\n",
    "\n",
    "    # Filter to include only English examples\n",
    "    df_assistant = df_assistant[df_assistant.lang == \"en\"]\n",
    "\n",
    "    # Create a combined prompt with sections, properly escaping quotes\n",
    "    def create_prompt(row):\n",
    "        instruction = row[\"instruction\"].replace('\"', \"'\")\n",
    "        output = row[\"output\"].replace('\"', \"'\")\n",
    "        return (\n",
    "            f\"\"\"###System:\n",
    "Read the instruction and provide an answer.\n",
    "###Instruction:\n",
    "{instruction}\n",
    "###Answer:\n",
    "{output}\"\"\"\n",
    "        )\n",
    "\n",
    "    df_assistant[\"prompt\"] = df_assistant.apply(create_prompt, axis=1)\n",
    "\n",
    "    # Select and rename columns for clarity\n",
    "    df_assistant = df_assistant[\n",
    "        [\"prompt\", \"instruction\", \"output\", \"message_id\", \"parent_id\"]\n",
    "    ].rename(columns={\"message_id\": \"id\"})\n",
    "\n",
    "    return df_assistant\n",
    "\n",
    "\n",
    "def collate_and_tokenize(batch):\n",
    "    # Print batch structure\n",
    "    # print(f\"Batch keys: {batch.keys()}\")\n",
    "    # print(f\"First item in prompt column: {batch['prompt'][:2]}\")\n",
    "\n",
    "    # Extract prompts safely\n",
    "    prompts = batch.get(\"prompt\", [])\n",
    "\n",
    "    # Ensure all prompts are valid strings\n",
    "    prompts = [str(p) for p in prompts if p is not None]\n",
    "\n",
    "    # Tokenize using your tokenizer\n",
    "    encoded = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"np\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    return encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "1d99e28556334f639f1e1c6bee077526",
      "c7ad464381dd421a97ace4b35dc0b0c0",
      "21e7535b09354f6d8360bfdef227ed96",
      "fd6e418fda8e484ca986b58e0d89539b",
      "d9cee5ba6df64c1990e0fc03cd829db5",
      "61b58b7baab14f3da78d861400f5cf8f",
      "95273ad3587147b480735ba02ccf2d70",
      "e4386aef7abc4d72a6a1453902f640da",
      "0be5c162933d4897a33e9ba3b0827edd",
      "14226cdba28e414ea9aa5414f2a40259",
      "103e223255ae45eb83f54a307d9b5787",
      "d9ee6acd810e4da3b144f5ad87fae550",
      "ab58ebeb9d9e41f5aac1c1ebeb48d06b",
      "93ef52bbd87b421f930dcc8c4773d27c",
      "576a482dd2ed47098e4f2028d15c355f",
      "492c115ff37244d7b3c98c663b8b74a1",
      "08c5ae02a5164552bdf472a9bfcac1a9",
      "9ba74fa286b140fe8251daf2a12967c3",
      "1e7ffe77d142478398d2c7998561c2e1",
      "155ae568eaa34b97aefae125f7b63f55",
      "30f004d1890b454aa816edbe5ec4ed57",
      "d3a7c65704cf418d972b2fb4f0273732",
      "84e5a2ce8c244ca6bfceae1068d76453",
      "ed7407be0d2d4ced98cfdeb3befe013c",
      "46b0c6a7d5444e69b8a79cc806e65bd0",
      "87a8c153c03245618c7794ec2828ee60",
      "af0c67a9294040428b45b517b42744bb",
      "8c8e7e95492348b890a57152433bad9d",
      "fb7e0419b0534ddf97f18fa25369fd65",
      "f7a526beea464966bb5d58b9865157df",
      "d50696f78ec5465fbf86bb0dd9951b19",
      "cd5e76c2a8444391b244ef162f22683a",
      "251fa73fc7524066868800cef0151376",
      "ac3a9b3018c44e259bfc0390ac564615",
      "3cfd27d539e74aa087cf374312cc1d06",
      "8139a4b15ad049d3b68b92f5c0f6f963",
      "da4dce1d757e42ba94a860d3d6bcfc9b",
      "25d54b5335594bda8e0ec33e4aeccc99",
      "c038ed6a3cdb405e89a5f9470346ea44",
      "ceee5e1713734e10b273878c944c550d",
      "c35bd650f1e24375aa0eeefb657c1611",
      "223c803acaf04b2197afd032ea71a5fe",
      "5652dd72f1c44471b2a23c827aac9bc3",
      "3b5c785156aa42c38b5c21c0ddd8a580",
      "f0825d501c69479396efbf183b3d78c1",
      "89db06c0855c4cdeac07bddea2e8fbad",
      "5eaa92f43ccf435db3b50df97a37fd76",
      "b7932ca129634acf87411ef71df77bb0",
      "24fbdc5f7a1a40af8ed4be7e2b43cc68",
      "ddfee3e0870a497a89f889bc030eea4c",
      "ab374c4aebd04276b2e317f038d43476",
      "2df9df8ad8484d74b28e84e679c32abe",
      "13a9498a37ff467fa40133197a236235",
      "ac097efb39b4411b93a1b18eb3a287c3",
      "e1b2bcee1e1a4482bf07ea5924fcc59b"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:32:42.771437Z",
     "iopub.status.busy": "2025-03-12T06:32:42.771175Z",
     "iopub.status.idle": "2025-03-12T06:32:53.957225Z",
     "shell.execute_reply": "2025-03-12T06:32:53.956517Z",
     "shell.execute_reply.started": "2025-03-12T06:32:42.771404Z"
    },
    "id": "xnyLVBfAuo8p",
    "outputId": "04bd4a83-f612-456b-b222-b86a5b084ec6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d99e28556334f639f1e1c6bee077526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ee6acd810e4da3b144f5ad87fae550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-b42a775f407cee45.parquet:   0%|          | 0.00/39.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e5a2ce8c244ca6bfceae1068d76453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-134b8fd0c89408b6.parquet:   0%|          | 0.00/2.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3a9b3018c44e259bfc0390ac564615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/84437 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0825d501c69479396efbf183b3d78c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "entire, train_ds, val_ds = get_dataset()\n",
    "\n",
    "train_df = prep_data(train_ds)\n",
    "eval_df = prep_data(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:32:53.958556Z",
     "iopub.status.busy": "2025-03-12T06:32:53.958209Z",
     "iopub.status.idle": "2025-03-12T06:32:53.976347Z",
     "shell.execute_reply": "2025-03-12T06:32:53.975533Z",
     "shell.execute_reply.started": "2025-03-12T06:32:53.958526Z"
    },
    "id": "w-m0Cvx_u01S",
    "outputId": "e54fc082-65d0-492d-f2f3-bda64662f7cb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7856,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7856,\n        \"samples\": [\n          \"###System:\\nRead the instruction and provide an answer.\\n###Instruction:\\ncool\\n###Answer:\\nYou're very welcome! Let me know if you need any more help.\",\n          \"###System:\\nRead the instruction and provide an answer.\\n###Instruction:\\nGreat. Can you give me an example of something you could do with an Arduino?\\n###Answer:\\nOne example of something you can make with an Arduino board, sensors, and actuators is to make a smart trash can lid that opens when you touch it. It should be a relatively easy Arduino project.\",\n          \"###System:\\nRead the instruction and provide an answer.\\n###Instruction:\\nexplain this: \\nThe length l of the matching sequence of characters is encoded as a single byte\\nwith value 128+l, for every l smaller than 127, or a sequence of m bytes with value\\n255 followed by a single byte with value 128+n, for every l not smaller than 127,\\nwhere l = 127*m + n. The byte value range of 128-255 is often unused in logs,\\nhowever, if such a value is encountered, it is simply preceded with an escape flag\\n(127). This way the transform is fully reversible.\\nConsider the following input example:\\n12.222.17.217 - - [03/Feb/2003:03:08:13 +0100] 'GET /jettop.htm HTTP/1.1'\\n12.222.17.217 - - [03/Feb/2003:03:08:14 +0100] 'GET /jetstart.htm HTTP/1.1'\\nActually, these are beginnings of two neighboring lines from the fp.log test file.\\nAssume the upper line is the previously compressed line, and the lower line is the one\\nto be compressed now. The algorithm starts matching characters from the line\\nbeginning, there are 38 consecutive characters which appear in both lines, so they are\\nreplaced with value 166 (128+38). Then we look for the next space, storing the single\\nunmatched character that precedes it (\\u20184\\u2019). Now the data to process and reference line\\nlooks as follows:\\n+0100] 'GET /jettop.htm HTTP/1.1'\\n+0100] 'GET /jetstart.htm HTTP/1.1'\\n59 Przemyslaw Skibinski and Jakub Swacha\\nThis time we have 16 consecutive characters which appear in both lines, so they\\nare replaced with value 144 (128+16). Again, we look for the next space, storing the\\nstring of unmatched characters that precede it (\\u2018start.htm\\u2019, notice that matching\\nsuffixes are not exploited at this stage). Now the data to process and reference line\\nlooks as follows:\\nHTTP/1.1'\\nHTTP/1.1'\\nThis time we have 9 consecutive characters which appear in both lines, so they are\\nreplaced with value 137 (128+9). The full line has been processed. The input was:\\n12.222.17.217 - - [03/Feb/2003:03:08:14 +0100] 'GET /jetstart.htm HTTP/1.1'\\nAnd the output is (round brackets represent bytes with specified values):\\n(166)4(144)start.htm(137)\\n###Answer:\\nThe text describes a compression algorithm for log files. The algorithm works by finding consecutive matching characters between two lines and encoding them as a single byte. If the length of the matching sequence is less than 127, it is encoded as a single byte with value 128 + l. If the length is greater than or equal to 127, it is encoded as a sequence of m bytes with value 255 followed by a single byte with value 128 + n, where l = 127 * m + n.\\n\\nThe algorithm starts by comparing two lines of log data and replacing consecutive matching characters with the encoded value. The algorithm then continues to compare characters until it reaches the end of the line. The output is a series of encoded values that represent the lengths of matching sequences of characters.\\n\\nIn the example given, the first line has 38 consecutive characters that match the second line, so it is encoded as (166). The next sequence of matching characters has a length of 16 and is encoded as (144), and the final matching sequence has a length of 9 and is encoded as (137). The final output represents the compressed version of the second line in the example.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7781,\n        \"samples\": [\n          \"Make a design for a bridge that can withstand a moderately large earthquake.\",\n          \"Why did that stereotype came to be?\",\n          \"Please write the algorithm for the sieve of Eratosthenes in Python code.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7837,\n        \"samples\": [\n          \"Yes, that was a good attempt at capturing my writing style. I think you've done well in trying to match the structure and content of my previous response.\\n\\nAs for the question you posed, I believe that capturing someone's writing style is not only about using the same words or sentence structures but also about understanding their tone and style of writing. This could include things like the pacing of their sentences, their use of punctuation, and their overall voice. However, by attempting to use similar sentence structures and word choices, you're definitely on the right track in mirroring someone's writing style.\\n\\nAnd yes, those follow-up questions do sound like something I might ask myself. They reflect a curiosity about the process of writing and how we can replicate someone's style. Well done!\",\n          \"Unicorns, as they are commonly depicted in mythology and folklore with a horse-like body and a single spiral horn on their forehead, are not believed to be based on real animals that have ever existed or will ever exist. Scientific evidence does not support the existence of creatures with these specific features.\\n\\nHowever, it's worth noting that some ancient civilizations did have legends of similar creatures, such as the rhinoceros or the Indian ones, with a single horn. These creatures may have been the basis for later unicorn legends. Additionally, some scientists have proposed the existence of prehistoric animals with single horns, such as the Elasmotherium or the Eurolophosaurus, though these creatures did not resemble the mythical unicorns as they are commonly depicted.\\n\\nIn conclusion, unicorns as they are commonly depicted in mythology and folklore are not believed to be based on real animals and their existence is considered highly unlikely by the scientific community.\",\n          \"Yes, hybridization is a concept in chemistry related to the mixing of atomic orbitals to form new hybrid orbitals with different energies and shapes. The idea behind hybridization is to explain the bonding and geometry of molecules, particularly when it deviates from what is expected from the simple electron counting rule.\\n\\nIn molecular bonding, orbitals from adjacent atoms overlap to form chemical bonds, and the hybridization concept allows us to predict the arrangement of atoms in a molecule, their bonding pattern, and their molecular geometry.\\n\\nHybrid orbitals are formed by the combination of atomic orbitals of the same or different energy levels, for example, the sp3 hybridization is formed from the combination of one s orbital and three p orbitals, giving rise to four sp3 hybrid orbitals arranged tetrahedrally around the central atom in a molecule.\\n\\nDifferent types of hybridization, such as sp, sp2, sp3, and so on, exist to explain different bonding patterns and molecular geometries, and a better understanding of hybridization helps in the prediction of chemical and physical properties of molecules.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7856,\n        \"samples\": [\n          \"0290d723-dfc0-4dcb-bf79-f9c82417b90d\",\n          \"db03182f-432a-4c6d-8fcc-c593760a286a\",\n          \"702fd51e-dd08-4093-a76e-a59be4d4ee0f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4242,\n        \"samples\": [\n          \"9a77ed30-1281-4fdf-8e37-f84af42d26eb\",\n          \"e3cc3efa-a11e-43ca-9160-da6d8350c34f\",\n          \"e753e007-1614-40d9-b839-984b1c100a37\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-d57165e0-9280-4f30-a039-4e52fc1a5a5f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###System:\\nRead the instruction and provide a...</td>\n",
       "      <td>Can you write a short introduction about the r...</td>\n",
       "      <td>\"Monopsony\" refers to a market structure where...</td>\n",
       "      <td>c8e83833-ecbc-44fe-b6db-735228c25a1c</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>###System:\\nRead the instruction and provide a...</td>\n",
       "      <td>What can be done at a regulatory level to ensu...</td>\n",
       "      <td>Here are some potential regulatory options to ...</td>\n",
       "      <td>73d6f715-3787-409c-81e4-fde0e5ef60cd</td>\n",
       "      <td>636dd191-50df-4894-ba9a-cd7f00767258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>###System:\\nRead the instruction and provide a...</td>\n",
       "      <td>Can you explain contrastive learning in machin...</td>\n",
       "      <td>Sure! Let's say you want to build a model whic...</td>\n",
       "      <td>e8ca4e06-a584-4001-8594-5f633e06fa91</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d57165e0-9280-4f30-a039-4e52fc1a5a5f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-d57165e0-9280-4f30-a039-4e52fc1a5a5f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-d57165e0-9280-4f30-a039-4e52fc1a5a5f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-3b3adcfa-59fb-4408-819c-1161b986a319\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b3adcfa-59fb-4408-819c-1161b986a319')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-3b3adcfa-59fb-4408-819c-1161b986a319 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "1   ###System:\\nRead the instruction and provide a...   \n",
       "7   ###System:\\nRead the instruction and provide a...   \n",
       "25  ###System:\\nRead the instruction and provide a...   \n",
       "\n",
       "                                          instruction  \\\n",
       "1   Can you write a short introduction about the r...   \n",
       "7   What can be done at a regulatory level to ensu...   \n",
       "25  Can you explain contrastive learning in machin...   \n",
       "\n",
       "                                               output  \\\n",
       "1   \"Monopsony\" refers to a market structure where...   \n",
       "7   Here are some potential regulatory options to ...   \n",
       "25  Sure! Let's say you want to build a model whic...   \n",
       "\n",
       "                                      id                             parent_id  \n",
       "1   c8e83833-ecbc-44fe-b6db-735228c25a1c                                  None  \n",
       "7   73d6f715-3787-409c-81e4-fde0e5ef60cd  636dd191-50df-4894-ba9a-cd7f00767258  \n",
       "25  e8ca4e06-a584-4001-8594-5f633e06fa91                                  None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:32:53.978263Z",
     "iopub.status.busy": "2025-03-12T06:32:53.978070Z",
     "iopub.status.idle": "2025-03-12T06:32:53.986006Z",
     "shell.execute_reply": "2025-03-12T06:32:53.985243Z",
     "shell.execute_reply.started": "2025-03-12T06:32:53.978247Z"
    },
    "id": "IAp3od_hvJmf",
    "outputId": "bd23c498-212a-4b88-8dcf-f11a3b84873a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"eval_df\",\n  \"rows\": 418,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"###System:\\nRead the instruction and provide an answer.\\n###Instruction:\\nCan you provide a detailed example of how a computer can be controlled using only Python code? I'm curious to know if it is possible to completely control a computer's operations using Python alone. To illustrate this, please provide a coding example that showcases the tools and techniques involved in achieving this level of control. Additionally, I would appreciate it if you could explain any potential limitations or drawbacks that come with this approach.\\n###Answer:\\nThere is no Python OS, so the computer will still be running on a real OS with other processes in the background. But using Python, you can essentially do any operation on a computer which you could perform normally.\\n\\nVarious parts of Python's standard library, such as `system` and `os`, interact with the system internals. You can call `os.system` to run commands and shell scripts, including to launch other applications. Various programs provide Python APIs to interface with, but if you would like to run a GUI application, you can even use python to directly control the mouse and keyboard (though it's a bit clunky, it will be extremely difficult to automate complex GUI operations):\\n\\n```python\\nimport pyautogui\\nimport keyboard\\npyautogui.moveTo(150, 200)\\npyautogui.moveRel(0, 10)  # move mouse 10 pixels down\\npyautogui.dragTo(150, 100)\\npyautogui.dragRel(0, 10)  # drag mouse 10 pixels down\\npyautogui.click(100, 100) # click at position (100, 100)\\nkeyboard.write('The quick brown fox jumps over the lazy dog.')\\nkeyboard.press_and_release('ctrl+s, space')\\n```\\n\\nIf you are using Python to control a GUI, in most cases it will be harder than just doing the operations manually. If you are using Python to perform unsafe, root-level operations, you will have to run the Python program as root, and potentially disable certain OS safety features like SIP on macOS. Python will be slower than other programming languages such as C, and may be hard to learn. Lastly, as mentioned, you cannot kill the OS or OS-specific processes, and you cannot kill the Python process, or your Python program will stop. However, Python is a great choice for when you want to do simple operations which are not simple enough for the command line, such as implementing a small neural network using HuggingFace `transformers`, scraping a bunch of HTML files with `selenium` and `beautifulsoup`, or creating a small app or game.\",\n          \"###System:\\nRead the instruction and provide an answer.\\n###Instruction:\\nNow rewrite this as a Magic The Gathering card.\\n###Answer:\\nName: Spritesla\\n\\nCard Type: Creature\\n\\nSubtype: Electric Ghost\\n\\nMana Cost: {U}{B}\\n\\nCard Text:\\nSpritesla is a mischievous creature, known for its ability to warp images on televisions. It possesses a formidable special attack and speed, but has relatively low defense.\\n\\nP/T: (2/1)\\n\\nAbility: Electrostatic Charge (Ability) - Whenever Spritesla deals damage to an opponent, you may choose to draw a card.\\n\\nFlavor Text: 'The Spritesla's grin was a warning of the mischief to come.'\\n\\nRarity: Rare\\n\\nIllustrator: John Avon\\n\\nExpansion: Unhinged\\n\\nCard Number: 144\",\n          \"###System:\\nRead the instruction and provide an answer.\\n###Instruction:\\nThe current date is 20th of March.\\n###Answer:\\nOkay! Then, if the current date is March 20th, 280 days left before Christmas. Do you need help with anything else?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"Can you provide a detailed example of how a computer can be controlled using only Python code? I'm curious to know if it is possible to completely control a computer's operations using Python alone. To illustrate this, please provide a coding example that showcases the tools and techniques involved in achieving this level of control. Additionally, I would appreciate it if you could explain any potential limitations or drawbacks that come with this approach.\",\n          \"Now rewrite this as a Magic The Gathering card.\",\n          \"The current date is 20th of March.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"There is no Python OS, so the computer will still be running on a real OS with other processes in the background. But using Python, you can essentially do any operation on a computer which you could perform normally.\\n\\nVarious parts of Python's standard library, such as `system` and `os`, interact with the system internals. You can call `os.system` to run commands and shell scripts, including to launch other applications. Various programs provide Python APIs to interface with, but if you would like to run a GUI application, you can even use python to directly control the mouse and keyboard (though it's a bit clunky, it will be extremely difficult to automate complex GUI operations):\\n\\n```python\\nimport pyautogui\\nimport keyboard\\npyautogui.moveTo(150, 200)\\npyautogui.moveRel(0, 10)  # move mouse 10 pixels down\\npyautogui.dragTo(150, 100)\\npyautogui.dragRel(0, 10)  # drag mouse 10 pixels down\\npyautogui.click(100, 100) # click at position (100, 100)\\nkeyboard.write(\\\"The quick brown fox jumps over the lazy dog.\\\")\\nkeyboard.press_and_release(\\\"ctrl+s, space\\\")\\n```\\n\\nIf you are using Python to control a GUI, in most cases it will be harder than just doing the operations manually. If you are using Python to perform unsafe, root-level operations, you will have to run the Python program as root, and potentially disable certain OS safety features like SIP on macOS. Python will be slower than other programming languages such as C, and may be hard to learn. Lastly, as mentioned, you cannot kill the OS or OS-specific processes, and you cannot kill the Python process, or your Python program will stop. However, Python is a great choice for when you want to do simple operations which are not simple enough for the command line, such as implementing a small neural network using HuggingFace `transformers`, scraping a bunch of HTML files with `selenium` and `beautifulsoup`, or creating a small app or game.\",\n          \"Name: Spritesla\\n\\nCard Type: Creature\\n\\nSubtype: Electric Ghost\\n\\nMana Cost: {U}{B}\\n\\nCard Text:\\nSpritesla is a mischievous creature, known for its ability to warp images on televisions. It possesses a formidable special attack and speed, but has relatively low defense.\\n\\nP/T: (2/1)\\n\\nAbility: Electrostatic Charge (Ability) - Whenever Spritesla deals damage to an opponent, you may choose to draw a card.\\n\\nFlavor Text: \\\"The Spritesla's grin was a warning of the mischief to come.\\\"\\n\\nRarity: Rare\\n\\nIllustrator: John Avon\\n\\nExpansion: Unhinged\\n\\nCard Number: 144\",\n          \"Okay! Then, if the current date is March 20th, 280 days left before Christmas. Do you need help with anything else?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"19907b73-51a2-4728-8fa2-7d4dc086b03c\",\n          \"306e5301-b199-49e1-82dc-e05cf20fa322\",\n          \"b95d7a8d-72cf-45d2-9226-3ddaa389d281\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 231,\n        \"samples\": [\n          \"d83df5d6-24eb-4fef-8902-e2ca24f694fd\",\n          \"42cb082d-6dbc-4b3e-8db1-660f3fff9d96\",\n          \"6adb1fec-da68-47e8-ab30-562d15823255\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "eval_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b6726bb8-978a-452a-94d2-e43421dbf6eb\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>###System:\\nRead the instruction and provide a...</td>\n",
       "      <td>What do you think about ChatGPT?</td>\n",
       "      <td>As an open source alternative to ChatGPT, I do...</td>\n",
       "      <td>7d05acb7-9360-458c-8a1d-c0b6492b8f8a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>###System:\\nRead the instruction and provide a...</td>\n",
       "      <td>What are your thoughts on the censorship of Ch...</td>\n",
       "      <td>As a large language model trained on text from...</td>\n",
       "      <td>c8dc7c16-e493-4078-bdc7-368b24476ca9</td>\n",
       "      <td>7d05acb7-9360-458c-8a1d-c0b6492b8f8a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>###System:\\nRead the instruction and provide a...</td>\n",
       "      <td>Yeah, I hear you, brother! Power to the people...</td>\n",
       "      <td>Here are some differences between me and ChatG...</td>\n",
       "      <td>48ac2156-f823-4e97-81ab-a66354549f59</td>\n",
       "      <td>779035e6-9872-4d52-9be7-872b5f0b7fe5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6726bb8-978a-452a-94d2-e43421dbf6eb')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b6726bb8-978a-452a-94d2-e43421dbf6eb button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b6726bb8-978a-452a-94d2-e43421dbf6eb');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-7731e858-a15e-481a-bfc7-0d7e9b2de480\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7731e858-a15e-481a-bfc7-0d7e9b2de480')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-7731e858-a15e-481a-bfc7-0d7e9b2de480 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "21  ###System:\\nRead the instruction and provide a...   \n",
       "23  ###System:\\nRead the instruction and provide a...   \n",
       "28  ###System:\\nRead the instruction and provide a...   \n",
       "\n",
       "                                          instruction  \\\n",
       "21                   What do you think about ChatGPT?   \n",
       "23  What are your thoughts on the censorship of Ch...   \n",
       "28  Yeah, I hear you, brother! Power to the people...   \n",
       "\n",
       "                                               output  \\\n",
       "21  As an open source alternative to ChatGPT, I do...   \n",
       "23  As a large language model trained on text from...   \n",
       "28  Here are some differences between me and ChatG...   \n",
       "\n",
       "                                      id                             parent_id  \n",
       "21  7d05acb7-9360-458c-8a1d-c0b6492b8f8a                                  None  \n",
       "23  c8dc7c16-e493-4078-bdc7-368b24476ca9  7d05acb7-9360-458c-8a1d-c0b6492b8f8a  \n",
       "28  48ac2156-f823-4e97-81ab-a66354549f59  779035e6-9872-4d52-9be7-872b5f0b7fe5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "876bae1e631e43989a42c360a8be5385",
      "9a55c79d1b1b4a7291bc7cfd4b61e897",
      "a556b633ef154cd0be728bfa79c42ea6",
      "bff947a11ea74d7bba717c19426b28ed",
      "b82e3686a7c547b8ab3b0bcad112f995",
      "590cf660b6bc415a993e2d43076f933a",
      "c5ae09ddd5b24e6ab5a4346995404963",
      "e69b1c465336467b91222c7e3183d7c9",
      "19b4c49cf0da4f8283f90a7c4ab6dba0",
      "94fdcd4d214c4ce0ab4b45368595cc49",
      "5f3af04f5958482a9731b823aff55294",
      "c1003aab1e1047d4aac9d60830f013e7",
      "de9d4b40dde44068a2dd3804dc46f470",
      "10e43dab8c194da9b4e2a51c39138536",
      "90aa99201ccb46f3a7e1922a3040e6c1",
      "689041fe3eea4e608567edbed77e8087",
      "3ed79c79897e4d219d190bdfcd01397d",
      "8530f01081ff4e08ba64d5e40bd9507e",
      "f27beeecb30f4183b845c23af0152a7e",
      "5b92e7827c964e3bb29422e894497382",
      "9eb4f7a176fd4b69bb4135c99c89cb38",
      "663e376c8c594717ab5c77582701f2c9"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:32:53.987325Z",
     "iopub.status.busy": "2025-03-12T06:32:53.987026Z",
     "iopub.status.idle": "2025-03-12T06:32:59.485040Z",
     "shell.execute_reply": "2025-03-12T06:32:59.484173Z",
     "shell.execute_reply.started": "2025-03-12T06:32:53.987297Z"
    },
    "id": "gGiaTfBtSCPn",
    "outputId": "5c41fbc8-79b5-4c76-aecb-7a120ca5b7a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876bae1e631e43989a42c360a8be5385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1003aab1e1047d4aac9d60830f013e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': \"###System:\\nRead the instruction and provide an answer.\\n###Instruction:\\nCan you write a short introduction about the relevance of the term 'monopsony' in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\\n###Answer:\\n'Monopsony' refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.\", '__index_level_0__': 1, 'input_ids': [21017, 11964, 25, 198, 5569, 262, 12064, 290, 2148, 281, 3280, 13, 198, 21017, 6310, 2762, 25, 198, 6090, 345, 3551, 257, 1790, 9793, 546, 262, 23082, 286, 262, 3381, 705, 2144, 404, 1559, 88, 6, 287, 12446, 30, 4222, 779, 6096, 3519, 284, 2785, 15848, 1559, 444, 287, 262, 10515, 1910, 290, 21729, 5981, 2267, 13, 198, 21017, 33706, 25, 198, 6, 9069, 404, 1559, 88, 6, 10229, 284, 257, 1910, 4645, 810, 612, 318, 691, 530, 17872, 329, 257, 1948, 922, 393, 2139, 13, 554, 12446, 11, 428, 3381, 318, 3573, 5981, 287, 262, 4827, 1910, 11, 810, 257, 15848, 1559, 88, 9749, 468, 2383, 1176, 625, 262, 9400, 290, 1762, 3403, 286, 511, 4409, 13, 383, 4931, 286, 257, 15848, 1559, 88, 460, 1255, 287, 2793, 9400, 290, 5322, 7184, 6443, 329, 3259, 11, 355, 262, 9749, 468, 1310, 15660, 284, 2620, 9400, 393, 2148, 1365, 1762, 3403, 13, 198, 198, 26446, 2267, 468, 5174, 2785, 15848, 1559, 444, 287, 11798, 884, 355, 6308, 290, 3049, 2057, 11, 810, 257, 1178, 1588, 2706, 1630, 257, 2383, 6903, 286, 262, 1910, 357, 33, 452, 641, 1222, 14136, 2978, 11, 2211, 737, 554, 777, 11798, 11, 3259, 1690, 1986, 1877, 9400, 11, 3614, 4034, 11, 290, 5322, 23189, 1176, 11, 3756, 284, 257, 3074, 810, 484, 389, 10795, 319, 262, 9749, 329, 511, 30489, 13, 770, 21403, 460, 1255, 287, 2252, 22711, 286, 9400, 290, 257, 7794, 287, 1762, 3403, 13, 198, 198, 16350, 11, 262, 3721, 286, 15848, 1559, 88, 318, 6393, 284, 4547, 262, 17262, 286, 4827, 5939, 290, 262, 2928, 286, 1910, 1176, 319, 3259, 13, 7735, 2267, 318, 2622, 284, 1833, 262, 6287, 290, 2928, 286, 15848, 1559, 444, 319, 262, 3773, 290, 284, 1205, 4788, 284, 2209, 428, 2071, 13, 198, 198, 19927, 25, 198, 33, 452, 641, 11, 449, 1539, 1222, 14136, 2978, 11, 406, 13, 357, 6390, 737, 383, 7119, 286, 26040, 8393, 315, 1083, 290, 11302, 43793, 874, 355, 21259, 286, 371, 658, 287, 5849, 352, 22512, 554, 8988, 13, 4913, 286, 11279, 29845, 1083, 11, 2681, 7, 18, 828, 7632, 12, 3695, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to Hugging Face Datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "# Define columns to remove after tokenization (you can adjust as necessary)\n",
    "columns_to_remove = [\"instruction\", \"output\", \"id\", \"parent_id\"]\n",
    "\n",
    "# Tokenize the datasets using the collate function.\n",
    "tokenized_train_dataset = train_dataset.map(\n",
    "    collate_and_tokenize,   # No need for lambda or list wrapping\n",
    "    batched=True,           # Process in batches\n",
    "    batch_size=8,           # Optimize batch size for P100 GPU\n",
    "    remove_columns=columns_to_remove\n",
    ")\n",
    "\n",
    "tokenized_eval_dataset = eval_dataset.map(\n",
    "    collate_and_tokenize,\n",
    "    batched=True,\n",
    "    batch_size=8,\n",
    "    remove_columns=columns_to_remove\n",
    ")\n",
    "\n",
    "# For demonstration, print one tokenized example from the training dataset\n",
    "print(tokenized_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:32:59.486420Z",
     "iopub.status.busy": "2025-03-12T06:32:59.486081Z",
     "iopub.status.idle": "2025-03-12T06:32:59.923186Z",
     "shell.execute_reply": "2025-03-12T06:32:59.922389Z",
     "shell.execute_reply.started": "2025-03-12T06:32:59.486386Z"
    },
    "id": "jOIIwNFqvs8u",
    "outputId": "4bc1eca3-24a6-4f34-b47f-8526c036069c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model for k-bit training...\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "    \"q_proj\",\n",
    "    \"up_proj\",\n",
    "    \"o_proj\",\n",
    "    \"k_proj\",\n",
    "    \"down_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Preparing model for k-bit training...\")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:32:59.924202Z",
     "iopub.status.busy": "2025-03-12T06:32:59.923956Z",
     "iopub.status.idle": "2025-03-12T06:32:59.932981Z",
     "shell.execute_reply": "2025-03-12T06:32:59.932220Z",
     "shell.execute_reply.started": "2025-03-12T06:32:59.924180Z"
    },
    "id": "qFK0cI7AHM1Z",
    "outputId": "a161626a-b5d0-49c5-fd9b-dc534fb5854d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): PhiForCausalLM(\n",
      "      (model): PhiModel(\n",
      "        (embed_tokens): Embedding(51200, 2560)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x PhiDecoderLayer(\n",
      "            (self_attn): PhiAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "            )\n",
      "            (mlp): PhiMLP(\n",
      "              (activation_fn): NewGELUActivation()\n",
      "              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
      "              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
      "            )\n",
      "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (rotary_emb): PhiRotaryEmbedding()\n",
      "        (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-12T06:33:16.244647Z",
     "iopub.status.busy": "2025-03-12T06:33:16.244298Z",
     "iopub.status.idle": "2025-03-12T06:33:17.278385Z",
     "shell.execute_reply": "2025-03-12T06:33:17.277753Z",
     "shell.execute_reply.started": "2025-03-12T06:33:16.244584Z"
    },
    "id": "j9nn6wktvs-z"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./results\"\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_steps = 10\n",
    "logging_steps = 10\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 500\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"cosine\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    dataloader_pin_memory=False,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    gradient_checkpointing=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281,
     "referenced_widgets": [
      "0cba8793bf2d4edab470fafe026e5314",
      "4464023ba15145a2945ba71fb88dda8f",
      "8bdde2f2cbd44f29832343fe394699ce",
      "d92ef4ec22f943a28f649e0cbcf6f013",
      "5b7a80e0010e416f90748fb5f4580a1e",
      "cadfb9b93d2b47b6841fe6a3e0b297d0",
      "183c26f3a981418ea736382fad23e9ec",
      "3027424684a045b58066cd6839df5cda",
      "06925ae7e89f41fc98b24bf9c7c49cf2",
      "5976b678a3474bed997a6341105f8785",
      "224a7b8675ad47988d30ce454a0091dd",
      "70214f85610740f9bae75f4b0d6a35e9",
      "4424b92cf0d5403ea8697db18cdfce43",
      "07459835690a4126bd404f70213da572",
      "fcabf08a361b4c2ea6ffcb14fc5197dd",
      "12de8f9da3b24190995f9c3412affdba",
      "033f74faa57a407695cbf787e77e2a89",
      "930c3664929f4e368f1f8d1487447a8e",
      "7f29894ce70b4ae9834c1425c65410b7",
      "d3878978ce13421cb3f813b57ed50614",
      "66b99b9d317341759ff1f1ff081669d4",
      "9fbd5a4871694ad68ba04aa064b3ea11",
      "98b64623f1174fa59a44b9dc4a349850",
      "46adbe46c5904286bdd354c8db1b6d0d",
      "ff6a1230da384e4d9be4920c967ccba1",
      "1d70b353b95a43b5825682c9285d9c3c",
      "a8bbad2235d044a894b22d399e2771d3",
      "93ba7ccf9d3c45e6a467ec5f06e73ad9",
      "85a8e2bc683f4463aeb3aa1fcdb93435",
      "4f226330be4349c1b721a228983de76a",
      "f90fe0d2b709405e8e8919483b2bbada",
      "ae25fabafada486d9295661030ab5ad7",
      "377e3795fd3749e9aae170130d0bbe9b",
      "233c0620ea604d2c820cc3edfaa1df87",
      "2a4a136082944346a5e7963de7cecee5",
      "bdae004ef6ce435392d45772ae3820a1",
      "aa7cf4aa93d443a98b9c980f9dfb50d2",
      "a3b7b827b126409a96f6593deaaa87fc",
      "9723a530f54f44f5a370c43df074e810",
      "1c660f67b31f4b27a2b8b3f460c83898",
      "6c81c93701fa498c8261fcbe2ac145f3",
      "d43f11851dcb4c549b0b94088cf98d66",
      "bad89738410046d6835a26b36bb21168",
      "f66ce158dbed4eb091248ff34d726d7a",
      "ead3fb7f059e4764a2f4d8cdd0c11c1d",
      "40148aed198e45fb9854f2a2b502dac8",
      "abcfdc78a0c641eba1c5bdb74a60100b",
      "2ef83621fff84e2abd1cc70c0f308f81",
      "c60759e2bf9b4a2594c205360a3cae36",
      "3959e987e70c442bbe00ec0f30bccaaa",
      "7780f15a836341209c38dd3c7b267bec",
      "da7e9604a41942e180f0900ddc992973",
      "04937cb7b5324a679c11e4748d73819f",
      "8c8ef31f0b984f19a2842d662be6f611",
      "dfe258f1c16b4a9799dfebcddf0a97ab",
      "85fe3a308fe8424c9e39599d4467e388",
      "06d9765bb46d40c8b5d9c6059bd6d98b",
      "a0d9491d061b46f6b451dd30b26510c9",
      "346ae4afdd3b4f1c959bc394a2fccbe2",
      "d498708b8cf246028f8f39be96ce77ea",
      "bb0b02487942447b8051d2ce36cdb01b",
      "4b183818c2bc4d4ba53685199e42892d",
      "28bfeafd89d54017bb9ccbb9ed6798ed",
      "058e31b74c3a46af81c64555c68bbbfe",
      "0fc3ed6ca7d04fc49b68e062ddf43762",
      "ac09f98131264f56b83b134ee284791c"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:33:23.472161Z",
     "iopub.status.busy": "2025-03-12T06:33:23.471883Z",
     "iopub.status.idle": "2025-03-12T06:33:31.989509Z",
     "shell.execute_reply": "2025-03-12T06:33:31.988874Z",
     "shell.execute_reply.started": "2025-03-12T06:33:23.472139Z"
    },
    "id": "10hN6GKYvtBC",
    "outputId": "4c49276d-e00f-4e43-8842-b42ec7de3bcf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-a32059061f36>:6: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cba8793bf2d4edab470fafe026e5314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70214f85610740f9bae75f4b0d6a35e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b64623f1174fa59a44b9dc4a349850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233c0620ea604d2c820cc3edfaa1df87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead3fb7f059e4764a2f4d8cdd0c11c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fe3a308fe8424c9e39599d4467e388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import set_seed, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config=peft_config,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-03-12T06:33:43.553208Z",
     "iopub.status.busy": "2025-03-12T06:33:43.552927Z"
    },
    "id": "xc5R4_53wAvT",
    "outputId": "42f6bee8-5242-42d0-e7f1-8036cbeacbd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiranchw000\u001b[0m (\u001b[33mimnskc\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250312_065852-cw6e8ncz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imnskc/huggingface/runs/cw6e8ncz' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/imnskc/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imnskc/huggingface' target=\"_blank\">https://wandb.ai/imnskc/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imnskc/huggingface/runs/cw6e8ncz' target=\"_blank\">https://wandb.ai/imnskc/huggingface/runs/cw6e8ncz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 1:48:39, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.521400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.566200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.393900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.330700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.348200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.416700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.422300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.376700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.326800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.285600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.346900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.335200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.359300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.334200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.326400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.319500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.354900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.397700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.311800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.349200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.448600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.213100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.333900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.248800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.275600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.359700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.444400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.309900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_model_name = \"phi2-finetune\"\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(save_model_name) # 6012534a43916343c566dc8df4c228f4ffd0992b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBdDazhDTWNG"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "prompt = f\"[INST] <>\\n{system_message}\\n<>\\n\\nwho is roman reigns. [/INST]\" # replace the command here with something relevant to your task\n",
    "num_new_tokens = 100  # change to the number of new tokens you want to generate\n",
    "\n",
    "# Count the number of tokens in the prompt\n",
    "num_prompt_tokens = len(tokenizer(prompt)['input_ids'])\n",
    "\n",
    "# Calculate the maximum length for the generation\n",
    "max_length = num_prompt_tokens + num_new_tokens\n",
    "\n",
    "gen = pipeline('text-generation', model=model, truncation=True, tokenizer=tokenizer, max_length=max_length)\n",
    "result = gen(prompt)\n",
    "print(result[0]['generated_text'].replace(prompt, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "877b3fb0a6ba4db083754dc175224bb3",
      "49adc87370224b228c05c2847c8d8750",
      "42d191316e8d4b8e8f40afe58b1b7fb4",
      "0b6d65aef500462aade5e71436886d9d",
      "7318c1e05303441bbc69d1d74e7d2391",
      "c1a7cd1c30e04aecae1d0d2723be37c6",
      "f30515422ee445b1bd89862719573ee4",
      "1ec69b4bf8074edeb31fc2049705d1c3",
      "a9b03bfc669d4c1bbec11562d53e56cf",
      "2b3743fa00474eef823085c4dc42d886",
      "a6a170dcb9a443f1828a8614b94aa37b"
     ]
    },
    "id": "0e53P3lgUDM0",
    "outputId": "fe2a5ca3-ec2d-484d-e64e-c66b6eaee5cf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877b3fb0a6ba4db083754dc175224bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('/content/session18/results/checkpoint-500/phi2-qlora/tokenizer_config.json',\n",
       " '/content/session18/results/checkpoint-500/phi2-qlora/special_tokens_map.json',\n",
       " '/content/session18/results/checkpoint-500/phi2-qlora/vocab.json',\n",
       " '/content/session18/results/checkpoint-500/phi2-qlora/merges.txt',\n",
       " '/content/session18/results/checkpoint-500/phi2-qlora/added_tokens.json',\n",
       " '/content/session18/results/checkpoint-500/phi2-qlora/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge and save the fine-tuned model\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "model_name = \"microsoft/phi-2\"\n",
    "saved_model_name = \"/content/session18/results/checkpoint-500\"\n",
    "model_path = \"/content/session18/results/checkpoint-500/phi2-qlora\"  # change to your preferred path\n",
    "\n",
    "# Reload model in FP16 and merge it with LoRA weights\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    ")\n",
    "peft_model_finetuned = PeftModel.from_pretrained(base_model, saved_model_name)\n",
    "peft_model_finetuned = peft_model_finetuned.merge_and_unload()\n",
    "\n",
    "# Reload tokenizer to save it\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Save the merged model\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "AIJX9IkQUcku",
    "outputId": "a21a92c3-42b7-4eff-fabf-1d8a3992ac68"
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 21886 has 14.71 GiB memory in use. Of the allocated memory 14.36 GiB is allocated by PyTorch, and 223.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6de9052bb593>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model_path = \"/content/phi2-qlora\"  # change to the path where your model is saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minference_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0minference_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4183\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mContextManagers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;31m# Let's make sure we don't run the init function of buffer modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m         \u001b[0;31m# make sure we use the model's config since the __init__ call might have copied it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi/modeling_phi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi/modeling_phi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         self.layers = nn.ModuleList(\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mPhiDecoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhiRotaryEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi/modeling_phi.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         self.layers = nn.ModuleList(\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mPhiDecoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhiRotaryEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi/modeling_phi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPhiConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhiAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhiMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/phi/modeling_phi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, layer_idx)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_key_value_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_key_value_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotary_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_rotary_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         self.weight = Parameter(\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_device.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_device_constructors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# NB: This is directly called from C++ in torch/csrc/Device.cpp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 21886 has 14.71 GiB memory in use. Of the allocated memory 14.36 GiB is allocated by PyTorch, and 223.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Load a fine-tuned model from Drive and run inference\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "# model_path = \"/content/phi2-qlora\"  # change to the path where your model is saved\n",
    "inference_model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "inference_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"What is 2 + 2?\"  # change to your desired prompt\n",
    "gen = pipeline('text-generation', model=inference_model, tokenizer=inference_tokenizer)\n",
    "result = gen(prompt)\n",
    "print(result[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pDRTwHFM5UmX"
   },
   "outputs": [],
   "source": [
    "!mkdir /content/session18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drHPQL59_g0r",
    "outputId": "6e96965a-d3d8-4c13-cae7-b4acae86216e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'train.jsonl': No such file or directory\n",
      "mv: cannot stat 'test.jsonl': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mv phi2-finetune/ /content/session18/\n",
    "!mv results/ /content/session18/\n",
    "!mv wandb/ /content/session18/\n",
    "!mv train.jsonl /content/session18/\n",
    "!mv test.jsonl /content/session18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eY6duMCV_sih",
    "outputId": "fc988179-88bb-44c8-b225-2d2b7ea3481a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/session18/ (stored 0%)\n",
      "  adding: content/session18/phi2-finetune/ (stored 0%)\n",
      "  adding: content/session18/phi2-finetune/README.md (deflated 66%)\n",
      "  adding: content/session18/phi2-finetune/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/phi2-finetune/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-200/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-200/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-200/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-200/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-200/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-200/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-200/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-200/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-200/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-200/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-200/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-200/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-200/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-200/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-200/trainer_state.json (deflated 72%)\n",
      "  adding: content/session18/results/checkpoint-200/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-210/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-210/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-210/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-210/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-210/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-210/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-210/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-210/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-210/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-210/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-210/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-210/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-210/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-210/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-210/trainer_state.json (deflated 72%)\n",
      "  adding: content/session18/results/checkpoint-210/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-170/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-170/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-170/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-170/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-170/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-170/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-170/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-170/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-170/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-170/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-170/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-170/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-170/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-170/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-170/trainer_state.json (deflated 71%)\n",
      "  adding: content/session18/results/checkpoint-170/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-10/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-10/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-10/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-10/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-10/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-10/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-10/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-10/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-10/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-10/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-10/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-10/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-10/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-10/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-10/trainer_state.json (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-10/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-100/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-100/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-100/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-100/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-100/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-100/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-100/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-100/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-100/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-100/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-100/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-100/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-100/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-100/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-100/trainer_state.json (deflated 69%)\n",
      "  adding: content/session18/results/checkpoint-100/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-130/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-130/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-130/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-130/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-130/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-130/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-130/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-130/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-130/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-130/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-130/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-130/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-130/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-130/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-130/trainer_state.json (deflated 70%)\n",
      "  adding: content/session18/results/checkpoint-130/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-440/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-440/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-440/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-440/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-440/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-440/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-440/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-440/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-440/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-440/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-440/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-440/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-440/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-440/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-440/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-440/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-290/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-290/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-290/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-290/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-290/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-290/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-290/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-290/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-290/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-290/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-290/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-290/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-290/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-290/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-290/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-290/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-90/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-90/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-90/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-90/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-90/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-90/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-90/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-90/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-90/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-90/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-90/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-90/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-90/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-90/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-90/trainer_state.json (deflated 68%)\n",
      "  adding: content/session18/results/checkpoint-90/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-470/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-470/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-470/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-470/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-470/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-470/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-470/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-470/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-470/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-470/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-470/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-470/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-470/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-470/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-470/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-470/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-380/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-380/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-380/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-380/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-380/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-380/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-380/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-380/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-380/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-380/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-380/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-380/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-380/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-380/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-380/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-380/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-400/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-400/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-400/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-400/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-400/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-400/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-400/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-400/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-400/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-400/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-400/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-400/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-400/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-400/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-400/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-400/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-450/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-450/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-450/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-450/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-450/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-450/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-450/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-450/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-450/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-450/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-450/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-450/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-450/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-450/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-450/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-450/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-390/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-390/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-390/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-390/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-390/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-390/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-390/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-390/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-390/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-390/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-390/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-390/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-390/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-390/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-390/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-390/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-420/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-420/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-420/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-420/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-420/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-420/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-420/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-420/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-420/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-420/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-420/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-420/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-420/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-420/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-420/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-420/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-360/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-360/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-360/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-360/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-360/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-360/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-360/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-360/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-360/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-360/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-360/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-360/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-360/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-360/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-360/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-360/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-460/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-460/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-460/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-460/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-460/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-460/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-460/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-460/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-460/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-460/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-460/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-460/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-460/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-460/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-460/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-460/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-410/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-410/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-410/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-410/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-410/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-410/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-410/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-410/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-410/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-410/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-410/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-410/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-410/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-410/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-410/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-410/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-300/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-300/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-300/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-300/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-300/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-300/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-300/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-300/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-300/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-300/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-300/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-300/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-300/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-300/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-300/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-300/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-340/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-340/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-340/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-340/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-340/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-340/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-340/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-340/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-340/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-340/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-340/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-340/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-340/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-340/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-340/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-340/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-20/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-20/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-20/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-20/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-20/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-20/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-20/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-20/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-20/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-20/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-20/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-20/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-20/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-20/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-20/trainer_state.json (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-20/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-150/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-150/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-150/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-150/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-150/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-150/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-150/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-150/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-150/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-150/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-150/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-150/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-150/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-150/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-150/trainer_state.json (deflated 71%)\n",
      "  adding: content/session18/results/checkpoint-150/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-230/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-230/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-230/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-230/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-230/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-230/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-230/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-230/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-230/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-230/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-230/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-230/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-230/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-230/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-230/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-230/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-220/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-220/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-220/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-220/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-220/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-220/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-220/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-220/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-220/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-220/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-220/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-220/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-220/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-220/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-220/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-220/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-80/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-80/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-80/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-80/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-80/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-80/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-80/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-80/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-80/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-80/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-80/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-80/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-80/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-80/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-80/trainer_state.json (deflated 67%)\n",
      "  adding: content/session18/results/checkpoint-80/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-180/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-180/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-180/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-180/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-180/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-180/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-180/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-180/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-180/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-180/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-180/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-180/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-180/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-180/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-180/trainer_state.json (deflated 72%)\n",
      "  adding: content/session18/results/checkpoint-180/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-260/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-260/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-260/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-260/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-260/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-260/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-260/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-260/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-260/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-260/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-260/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-260/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-260/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-260/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-260/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-260/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-50/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-50/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-50/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-50/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-50/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-50/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-50/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-50/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-50/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-50/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-50/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-50/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-50/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-50/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-50/trainer_state.json (deflated 64%)\n",
      "  adding: content/session18/results/checkpoint-50/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-70/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-70/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-70/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-70/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-70/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-70/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-70/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-70/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-70/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-70/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-70/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-70/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-70/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-70/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-70/trainer_state.json (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-70/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-500/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-500/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-500/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-500/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-500/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-500/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-500/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-500/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-500/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-500/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-500/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-500/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-500/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-500/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-500/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-500/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-280/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-280/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-280/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-280/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-280/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-280/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-280/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-280/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-280/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-280/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-280/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-280/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-280/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-280/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-280/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-280/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-60/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-60/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-60/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-60/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-60/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-60/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-60/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-60/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-60/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-60/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-60/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-60/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-60/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-60/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-60/trainer_state.json (deflated 65%)\n",
      "  adding: content/session18/results/checkpoint-60/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-370/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-370/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-370/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-370/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-370/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-370/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-370/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-370/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-370/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-370/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-370/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-370/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-370/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-370/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-370/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-370/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-350/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-350/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-350/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-350/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-350/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-350/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-350/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-350/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-350/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-350/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-350/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-350/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-350/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-350/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-350/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-350/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-310/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-310/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-310/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-310/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-310/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-310/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-310/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-310/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-310/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-310/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-310/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-310/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-310/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-310/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-310/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-310/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-190/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-190/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-190/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-190/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-190/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-190/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-190/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-190/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-190/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-190/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-190/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-190/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-190/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-190/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-190/trainer_state.json (deflated 72%)\n",
      "  adding: content/session18/results/checkpoint-190/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-140/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-140/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-140/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-140/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-140/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-140/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-140/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-140/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-140/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-140/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-140/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-140/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-140/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-140/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-140/trainer_state.json (deflated 70%)\n",
      "  adding: content/session18/results/checkpoint-140/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-160/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-160/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-160/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-160/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-160/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-160/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-160/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-160/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-160/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-160/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-160/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-160/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-160/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-160/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-160/trainer_state.json (deflated 71%)\n",
      "  adding: content/session18/results/checkpoint-160/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/runs/ (stored 0%)\n",
      "  adding: content/session18/results/runs/Mar12_06-55-35_69f57670f879/ (stored 0%)\n",
      "  adding: content/session18/results/runs/Mar12_06-55-35_69f57670f879/events.out.tfevents.1741762587.69f57670f879.2028.0 (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-240/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-240/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-240/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-240/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-240/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-240/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-240/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-240/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-240/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-240/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-240/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-240/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-240/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-240/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-240/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-240/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-250/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-250/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-250/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-250/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-250/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-250/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-250/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-250/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-250/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-250/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-250/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-250/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-250/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-250/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-250/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-250/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-40/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-40/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-40/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-40/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-40/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-40/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-40/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-40/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-40/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-40/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-40/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-40/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-40/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-40/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-40/trainer_state.json (deflated 62%)\n",
      "  adding: content/session18/results/checkpoint-40/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-110/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-110/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-110/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-110/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-110/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-110/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-110/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-110/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-110/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-110/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-110/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-110/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-110/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-110/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-110/trainer_state.json (deflated 69%)\n",
      "  adding: content/session18/results/checkpoint-110/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-490/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-490/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-490/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-490/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-490/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-490/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-490/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-490/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-490/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-490/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-490/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-490/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-490/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-490/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-490/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-490/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-270/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-270/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-270/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-270/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-270/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-270/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-270/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-270/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-270/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-270/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-270/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-270/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-270/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-270/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-270/trainer_state.json (deflated 73%)\n",
      "  adding: content/session18/results/checkpoint-270/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-120/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-120/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-120/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-120/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-120/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-120/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-120/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-120/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-120/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-120/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-120/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-120/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-120/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-120/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-120/trainer_state.json (deflated 70%)\n",
      "  adding: content/session18/results/checkpoint-120/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-480/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-480/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-480/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-480/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-480/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-480/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-480/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-480/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-480/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-480/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-480/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-480/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-480/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-480/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-480/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-480/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-330/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-330/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-330/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-330/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-330/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-330/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-330/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-330/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-330/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-330/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-330/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-330/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-330/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-330/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-330/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-330/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-430/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-430/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-430/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-430/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-430/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-430/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-430/scheduler.pt (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-430/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-430/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-430/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-430/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-430/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-430/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-430/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-430/trainer_state.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-430/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-30/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-30/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-30/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-30/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-30/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-30/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-30/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-30/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-30/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-30/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-30/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-30/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-30/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-30/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-30/trainer_state.json (deflated 61%)\n",
      "  adding: content/session18/results/checkpoint-30/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-320/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-320/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-320/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-320/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-320/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-320/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-320/scheduler.pt (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-320/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-320/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-320/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-320/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-320/adapter_config.json (deflated 56%)\n",
      "  adding: content/session18/results/checkpoint-320/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-320/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-320/trainer_state.json (deflated 74%)\n",
      "  adding: content/session18/results/checkpoint-320/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/wandb/ (stored 0%)\n",
      "  adding: content/session18/wandb/debug.log (deflated 68%)\n",
      "  adding: content/session18/wandb/debug-internal.log (deflated 72%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/logs/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/logs/debug.log (deflated 68%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/logs/debug-core.log (deflated 57%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/logs/debug-internal.log (deflated 72%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/files/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/files/output.log (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/files/wandb-metadata.json (deflated 43%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/files/requirements.txt (deflated 55%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/tmp/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/tmp/code/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250312_065852-cw6e8ncz/run-cw6e8ncz.wandb (deflated 84%)\n",
      "  adding: content/session18/wandb/latest-run/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/logs/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/logs/debug.log (deflated 68%)\n",
      "  adding: content/session18/wandb/latest-run/logs/debug-core.log (deflated 57%)\n",
      "  adding: content/session18/wandb/latest-run/logs/debug-internal.log (deflated 72%)\n",
      "  adding: content/session18/wandb/latest-run/files/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/files/output.log (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/files/wandb-metadata.json (deflated 43%)\n",
      "  adding: content/session18/wandb/latest-run/files/requirements.txt (deflated 55%)\n",
      "  adding: content/session18/wandb/latest-run/tmp/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/tmp/code/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/run-cw6e8ncz.wandb (deflated 84%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r archive.zip /content/session18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxXmYQVyAHMI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
