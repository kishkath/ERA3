{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErJ7_4ops5bl",
    "outputId": "a127cbcc-71fc-4bcb-e6fe-9ed1a72adb97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.1/342.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Install and import the necessary libraries\n",
    "!pip install torch\n",
    "!pip install -q -U accelerate peft bitsandbytes transformers trl einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IGkUjRaVtD9U"
   },
   "outputs": [],
   "source": [
    "### Load dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "def get_dataset():\n",
    "  dataset_loaded = load_dataset(\"OpenAssistant/oasst1\")\n",
    "  train_dataset = dataset_loaded[\"train\"].to_pandas()\n",
    "  val_dataset = dataset_loaded[\"validation\"].to_pandas()\n",
    "  return dataset_loaded, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8TKYfMBZunlr"
   },
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    df_assistant = df[(df.role == \"assistant\") & (df[\"rank\"] == 0.0)].copy()\n",
    "    df_prompter = df[(df.role == \"prompter\")].copy()\n",
    "    df_prompter = df_prompter.set_index(\"message_id\")\n",
    "    df_assistant[\"output\"] = df_assistant[\"text\"].values\n",
    "\n",
    "    inputs = []\n",
    "    parent_ids = []\n",
    "    for _, row in df_assistant.iterrows():\n",
    "        input = df_prompter.loc[row.parent_id]\n",
    "        inputs.append(input.text)\n",
    "        parent_ids.append(input.parent_id)\n",
    "\n",
    "    df_assistant[\"instruction\"] = inputs\n",
    "    df_assistant[\"parent_id\"] = parent_ids\n",
    "\n",
    "    df_assistant = df_assistant[df_assistant.lang == \"en\"]\n",
    "\n",
    "    df_assistant = df_assistant[\n",
    "        [\"instruction\", \"output\", \"message_id\", \"parent_id\"]\n",
    "    ].rename(columns={\"message_id\": \"id\"})\n",
    "\n",
    "    return df_assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301,
     "referenced_widgets": [
      "38a9bc5f6c79434bac562478ea92c4af",
      "785ece3c4df34600a444d3462a996ccb",
      "ab9e3c6b120f411096a3e6cd0284c833",
      "bd2dc7c0b34e43a2863d4f88ce9b024d",
      "8ea48c799ac4406faaf963a9e2faf6cf",
      "376fd299fcbe4be1a77845415f5ab054",
      "5f48b2d9c1e74f368057c79e1a3dcf4c",
      "a52c061db47b4388b10e4e7ab646aa6b",
      "7b9e82658b9c47399e0b5a607adce0cd",
      "7bd83e4504a74486a98b41c72dcaea76",
      "9289563335494a45bcf6a0745acc32a2",
      "cc170540a18348fd9b24386ea1609824",
      "8c04972458204584b49e68f1e5932ab1",
      "cd7e446fd2ed4aec9961ea74b6ff7b00",
      "22255340611040a4bc233972cf25ee30",
      "ac9b5959c9e240c9a6320a229a0e7fe8",
      "e363b2a32bdb49669cde3a82f87ff9b1",
      "9c4b062fa7934c5eab40c78ba634f18a",
      "3ee3ad131fdc4f69b2bbbe113417e591",
      "d7dbde50fa3641158b5054a5b340f5b5",
      "ecf71c6b0b1a4489802b3b7c26b8d1bc",
      "edd48d55ade24955aea9b9480e943a72",
      "91eb7b6aad0742d591ed8e4e8c5304dc",
      "48098e62c3ce43d9934e70fb9713e94b",
      "cf9a9255b4114e5aa5126cb6f24213d2",
      "763ccf22fecc4640bda684d3e46c5422",
      "bb4e094239b147e789500322b77240b2",
      "4d6dcce066f24d74a814064411ca8b02",
      "2896538414a44c7b8e1208ffcd9a1530",
      "252119354da344ab9aa42b71408f7467",
      "1872c254111b49bf9eccd609c0133407",
      "ef5e0ae7b4be432d96d804b354b5cbbb",
      "439bc46ea9af4af48fa3773cd0e4ca3d",
      "fbffbc9e22f347f5850c4fa8e3d5ad5c",
      "f7de340ee83c43818629d11b6ecbc93e",
      "bc79b15b1dc44e98b03a7fdf8fabdb76",
      "e8e89947cc644e65a4ca4fc13cbc91f2",
      "98f18c7a5c7d4b719c0a9bd917710c37",
      "2cf69c2d9a574b028f7979302950fb98",
      "7f1fd9d9855f46a2b83f7d53008a4529",
      "bc75fb805b274806b313bbd053d25957",
      "ae7f5ca5d3e34c45acca68a8f0de3ec0",
      "60e3ddaf07af4d978f2ea4fcf65716de",
      "6e0b22344aa1400d8a15ee7bc310a39e",
      "a598e5adbf6641e2a4e941ce9140715a",
      "501f8ae4aa96427693830542e3c71b45",
      "c2b9cee3f5c74fd283eeba655e45c79e",
      "195216eaef7b47558d41f2ccbe6233fc",
      "0ca6359e2f584d68b7cf394b760200d2",
      "be1a3ae8415246d9843dbbe12deda908",
      "150862e4230243e98a775ae0d7d4d534",
      "80e9b884b856469c9f62525a1265f225",
      "e8de9b12b2c449f0800110b0d7e324a2",
      "f2a9a9e80a0f4a449aa9e63e69299046",
      "236920830381439f8229f811cbfb5a3d"
     ]
    },
    "id": "xnyLVBfAuo8p",
    "outputId": "99dfa9c0-75d8-4af7-d576-4a48113ba7c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a9bc5f6c79434bac562478ea92c4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc170540a18348fd9b24386ea1609824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-b42a775f407cee45.parquet:   0%|          | 0.00/39.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91eb7b6aad0742d591ed8e4e8c5304dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-134b8fd0c89408b6.parquet:   0%|          | 0.00/2.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbffbc9e22f347f5850c4fa8e3d5ad5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/84437 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a598e5adbf6641e2a4e941ce9140715a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4401 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entire, train_ds, val_ds = get_dataset()\n",
    "\n",
    "train_df = prep_data(train_ds)\n",
    "eval_df = prep_data(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "w-m0Cvx_u01S",
    "outputId": "2f160ccd-891b-4f10-a7af-ff11d80cf2f6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7856,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7781,\n        \"samples\": [\n          \"Make a design for a bridge that can withstand a moderately large earthquake.\",\n          \"Why did that stereotype came to be?\",\n          \"Please write the algorithm for the sieve of Eratosthenes in Python code.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7837,\n        \"samples\": [\n          \"Yes, that was a good attempt at capturing my writing style. I think you've done well in trying to match the structure and content of my previous response.\\n\\nAs for the question you posed, I believe that capturing someone's writing style is not only about using the same words or sentence structures but also about understanding their tone and style of writing. This could include things like the pacing of their sentences, their use of punctuation, and their overall voice. However, by attempting to use similar sentence structures and word choices, you're definitely on the right track in mirroring someone's writing style.\\n\\nAnd yes, those follow-up questions do sound like something I might ask myself. They reflect a curiosity about the process of writing and how we can replicate someone's style. Well done!\",\n          \"Unicorns, as they are commonly depicted in mythology and folklore with a horse-like body and a single spiral horn on their forehead, are not believed to be based on real animals that have ever existed or will ever exist. Scientific evidence does not support the existence of creatures with these specific features.\\n\\nHowever, it's worth noting that some ancient civilizations did have legends of similar creatures, such as the rhinoceros or the Indian ones, with a single horn. These creatures may have been the basis for later unicorn legends. Additionally, some scientists have proposed the existence of prehistoric animals with single horns, such as the Elasmotherium or the Eurolophosaurus, though these creatures did not resemble the mythical unicorns as they are commonly depicted.\\n\\nIn conclusion, unicorns as they are commonly depicted in mythology and folklore are not believed to be based on real animals and their existence is considered highly unlikely by the scientific community.\",\n          \"Yes, hybridization is a concept in chemistry related to the mixing of atomic orbitals to form new hybrid orbitals with different energies and shapes. The idea behind hybridization is to explain the bonding and geometry of molecules, particularly when it deviates from what is expected from the simple electron counting rule.\\n\\nIn molecular bonding, orbitals from adjacent atoms overlap to form chemical bonds, and the hybridization concept allows us to predict the arrangement of atoms in a molecule, their bonding pattern, and their molecular geometry.\\n\\nHybrid orbitals are formed by the combination of atomic orbitals of the same or different energy levels, for example, the sp3 hybridization is formed from the combination of one s orbital and three p orbitals, giving rise to four sp3 hybrid orbitals arranged tetrahedrally around the central atom in a molecule.\\n\\nDifferent types of hybridization, such as sp, sp2, sp3, and so on, exist to explain different bonding patterns and molecular geometries, and a better understanding of hybridization helps in the prediction of chemical and physical properties of molecules.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7856,\n        \"samples\": [\n          \"0290d723-dfc0-4dcb-bf79-f9c82417b90d\",\n          \"db03182f-432a-4c6d-8fcc-c593760a286a\",\n          \"702fd51e-dd08-4093-a76e-a59be4d4ee0f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4242,\n        \"samples\": [\n          \"9a77ed30-1281-4fdf-8e37-f84af42d26eb\",\n          \"e3cc3efa-a11e-43ca-9160-da6d8350c34f\",\n          \"e753e007-1614-40d9-b839-984b1c100a37\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ec6e410d-c1ee-4e1e-a3b7-871e2c776699\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can you write a short introduction about the r...</td>\n",
       "      <td>\"Monopsony\" refers to a market structure where...</td>\n",
       "      <td>c8e83833-ecbc-44fe-b6db-735228c25a1c</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What can be done at a regulatory level to ensu...</td>\n",
       "      <td>Here are some potential regulatory options to ...</td>\n",
       "      <td>73d6f715-3787-409c-81e4-fde0e5ef60cd</td>\n",
       "      <td>636dd191-50df-4894-ba9a-cd7f00767258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Can you explain contrastive learning in machin...</td>\n",
       "      <td>Sure! Let's say you want to build a model whic...</td>\n",
       "      <td>e8ca4e06-a584-4001-8594-5f633e06fa91</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I didn't understand how pulling and pushing wo...</td>\n",
       "      <td>It has to do with a process called differentia...</td>\n",
       "      <td>4c7578c0-f45b-4dd0-a1a1-24a189658a41</td>\n",
       "      <td>e8ca4e06-a584-4001-8594-5f633e06fa91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I want to start doing astrophotography as a ho...</td>\n",
       "      <td>Getting started in astrophotography can seem d...</td>\n",
       "      <td>19cb94ab-d6ab-4dbd-b408-70ffbd9b595c</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec6e410d-c1ee-4e1e-a3b7-871e2c776699')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ec6e410d-c1ee-4e1e-a3b7-871e2c776699 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ec6e410d-c1ee-4e1e-a3b7-871e2c776699');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ee115a88-c253-4229-ac5e-5959c6da38c6\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee115a88-c253-4229-ac5e-5959c6da38c6')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ee115a88-c253-4229-ac5e-5959c6da38c6 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                          instruction  \\\n",
       "1   Can you write a short introduction about the r...   \n",
       "7   What can be done at a regulatory level to ensu...   \n",
       "25  Can you explain contrastive learning in machin...   \n",
       "27  I didn't understand how pulling and pushing wo...   \n",
       "38  I want to start doing astrophotography as a ho...   \n",
       "\n",
       "                                               output  \\\n",
       "1   \"Monopsony\" refers to a market structure where...   \n",
       "7   Here are some potential regulatory options to ...   \n",
       "25  Sure! Let's say you want to build a model whic...   \n",
       "27  It has to do with a process called differentia...   \n",
       "38  Getting started in astrophotography can seem d...   \n",
       "\n",
       "                                      id                             parent_id  \n",
       "1   c8e83833-ecbc-44fe-b6db-735228c25a1c                                  None  \n",
       "7   73d6f715-3787-409c-81e4-fde0e5ef60cd  636dd191-50df-4894-ba9a-cd7f00767258  \n",
       "25  e8ca4e06-a584-4001-8594-5f633e06fa91                                  None  \n",
       "27  4c7578c0-f45b-4dd0-a1a1-24a189658a41  e8ca4e06-a584-4001-8594-5f633e06fa91  \n",
       "38  19cb94ab-d6ab-4dbd-b408-70ffbd9b595c                                  None  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IAp3od_hvJmf",
    "outputId": "e523cfa3-d8b8-4bf2-e512-4eebd9e4eef1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"eval_df\",\n  \"rows\": 418,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"Can you provide a detailed example of how a computer can be controlled using only Python code? I'm curious to know if it is possible to completely control a computer's operations using Python alone. To illustrate this, please provide a coding example that showcases the tools and techniques involved in achieving this level of control. Additionally, I would appreciate it if you could explain any potential limitations or drawbacks that come with this approach.\",\n          \"Now rewrite this as a Magic The Gathering card.\",\n          \"The current date is 20th of March.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"There is no Python OS, so the computer will still be running on a real OS with other processes in the background. But using Python, you can essentially do any operation on a computer which you could perform normally.\\n\\nVarious parts of Python's standard library, such as `system` and `os`, interact with the system internals. You can call `os.system` to run commands and shell scripts, including to launch other applications. Various programs provide Python APIs to interface with, but if you would like to run a GUI application, you can even use python to directly control the mouse and keyboard (though it's a bit clunky, it will be extremely difficult to automate complex GUI operations):\\n\\n```python\\nimport pyautogui\\nimport keyboard\\npyautogui.moveTo(150, 200)\\npyautogui.moveRel(0, 10)  # move mouse 10 pixels down\\npyautogui.dragTo(150, 100)\\npyautogui.dragRel(0, 10)  # drag mouse 10 pixels down\\npyautogui.click(100, 100) # click at position (100, 100)\\nkeyboard.write(\\\"The quick brown fox jumps over the lazy dog.\\\")\\nkeyboard.press_and_release(\\\"ctrl+s, space\\\")\\n```\\n\\nIf you are using Python to control a GUI, in most cases it will be harder than just doing the operations manually. If you are using Python to perform unsafe, root-level operations, you will have to run the Python program as root, and potentially disable certain OS safety features like SIP on macOS. Python will be slower than other programming languages such as C, and may be hard to learn. Lastly, as mentioned, you cannot kill the OS or OS-specific processes, and you cannot kill the Python process, or your Python program will stop. However, Python is a great choice for when you want to do simple operations which are not simple enough for the command line, such as implementing a small neural network using HuggingFace `transformers`, scraping a bunch of HTML files with `selenium` and `beautifulsoup`, or creating a small app or game.\",\n          \"Name: Spritesla\\n\\nCard Type: Creature\\n\\nSubtype: Electric Ghost\\n\\nMana Cost: {U}{B}\\n\\nCard Text:\\nSpritesla is a mischievous creature, known for its ability to warp images on televisions. It possesses a formidable special attack and speed, but has relatively low defense.\\n\\nP/T: (2/1)\\n\\nAbility: Electrostatic Charge (Ability) - Whenever Spritesla deals damage to an opponent, you may choose to draw a card.\\n\\nFlavor Text: \\\"The Spritesla's grin was a warning of the mischief to come.\\\"\\n\\nRarity: Rare\\n\\nIllustrator: John Avon\\n\\nExpansion: Unhinged\\n\\nCard Number: 144\",\n          \"Okay! Then, if the current date is March 20th, 280 days left before Christmas. Do you need help with anything else?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 418,\n        \"samples\": [\n          \"19907b73-51a2-4728-8fa2-7d4dc086b03c\",\n          \"306e5301-b199-49e1-82dc-e05cf20fa322\",\n          \"b95d7a8d-72cf-45d2-9226-3ddaa389d281\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 231,\n        \"samples\": [\n          \"d83df5d6-24eb-4fef-8902-e2ca24f694fd\",\n          \"42cb082d-6dbc-4b3e-8db1-660f3fff9d96\",\n          \"6adb1fec-da68-47e8-ab30-562d15823255\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "eval_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-244eb26d-6c06-432b-a0c4-ca8e8d5bc522\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What do you think about ChatGPT?</td>\n",
       "      <td>As an open source alternative to ChatGPT, I do...</td>\n",
       "      <td>7d05acb7-9360-458c-8a1d-c0b6492b8f8a</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What are your thoughts on the censorship of Ch...</td>\n",
       "      <td>As a large language model trained on text from...</td>\n",
       "      <td>c8dc7c16-e493-4078-bdc7-368b24476ca9</td>\n",
       "      <td>7d05acb7-9360-458c-8a1d-c0b6492b8f8a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Yeah, I hear you, brother! Power to the people...</td>\n",
       "      <td>Here are some differences between me and ChatG...</td>\n",
       "      <td>48ac2156-f823-4e97-81ab-a66354549f59</td>\n",
       "      <td>779035e6-9872-4d52-9be7-872b5f0b7fe5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Can you please provide me the names of the two...</td>\n",
       "      <td>Yes. Given that you're requesting information ...</td>\n",
       "      <td>99433b0b-566a-48c6-a470-8c4c1dc5957f</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>How would the Future of AI in 10 Years look?</td>\n",
       "      <td>Predicting the future is always a challenging ...</td>\n",
       "      <td>b5de9e83-d570-42b3-a6cd-ca731fb2e4de</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-244eb26d-6c06-432b-a0c4-ca8e8d5bc522')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-244eb26d-6c06-432b-a0c4-ca8e8d5bc522 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-244eb26d-6c06-432b-a0c4-ca8e8d5bc522');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2ddb3e34-6285-4904-ba42-f82fc06cd430\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ddb3e34-6285-4904-ba42-f82fc06cd430')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2ddb3e34-6285-4904-ba42-f82fc06cd430 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                          instruction  \\\n",
       "21                   What do you think about ChatGPT?   \n",
       "23  What are your thoughts on the censorship of Ch...   \n",
       "28  Yeah, I hear you, brother! Power to the people...   \n",
       "33  Can you please provide me the names of the two...   \n",
       "42       How would the Future of AI in 10 Years look?   \n",
       "\n",
       "                                               output  \\\n",
       "21  As an open source alternative to ChatGPT, I do...   \n",
       "23  As a large language model trained on text from...   \n",
       "28  Here are some differences between me and ChatG...   \n",
       "33  Yes. Given that you're requesting information ...   \n",
       "42  Predicting the future is always a challenging ...   \n",
       "\n",
       "                                      id                             parent_id  \n",
       "21  7d05acb7-9360-458c-8a1d-c0b6492b8f8a                                  None  \n",
       "23  c8dc7c16-e493-4078-bdc7-368b24476ca9  7d05acb7-9360-458c-8a1d-c0b6492b8f8a  \n",
       "28  48ac2156-f823-4e97-81ab-a66354549f59  779035e6-9872-4d52-9be7-872b5f0b7fe5  \n",
       "33  99433b0b-566a-48c6-a470-8c4c1dc5957f                                  None  \n",
       "42  b5de9e83-d570-42b3-a6cd-ca731fb2e4de                                  None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tybJ3IiWyI41"
   },
   "outputs": [],
   "source": [
    "# Save the dataframes to .jsonl files\n",
    "\n",
    "train_df.to_json('train.jsonl', orient='records', lines=True)\n",
    "eval_df.to_json('test.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "ca2d777afc0249a1a01abbd2494c61dc",
      "108ee0a6cc77424d8906b8e8c8aa0dd2",
      "1acd169f0c814b2bab45b5ac5a767cec",
      "319801aed8f245af81ec55255ce3d2c8",
      "c42896aaf8294be7a4ec0615ffe91f65",
      "cc481e5e95d94c35a074a4da8f3f1414",
      "f29a68c6e9534b93bcc1d9df4d7f177b",
      "57d92d8b148745eebbfafd11d5e779b1",
      "adafba685aa24b8ebbc301906c471044",
      "be0b698cb51c4757b4ffa7953b9be26a",
      "63d4588ca4554807853d32e6c2205f97",
      "6779734b2d7d4fc493c1ac695dad2dca",
      "ac79cca26c77490abd0e30f8f4688915",
      "67fddb502973428d97a071aea5a99b68",
      "d89f772765c8472981de1f8cf96f249e",
      "74d14f37df0b407d93ae78a5f53b11b5",
      "7e1cc7346d3a4fa9b033325c1f985690",
      "3d84e7d7c6c541bb9c43a1d1610d736f",
      "b8414347bccf4e7284c21b1ab81b363a",
      "a6987d8d38ca407baf3c8759cc8392eb",
      "188aa57422894a1a8e5119d9c0380b80",
      "aeb598537349485d9f9ab6718eb29efa",
      "33674c1d685a4bca815a41d8658e0ecb",
      "4fa3c13da1c04aa1b576dc8b2947ad76",
      "ac73abe0ae7b4d8b9b574a4787b01b0e",
      "e8e0b84812534f31bd627700bdeb772d",
      "93657605d11c4299bbba0b96b2fbe23f",
      "af323bf50a1c42ca906a9d567350a86d",
      "2ed2c7889ffb45b887b11952cd7a3a0f",
      "1eb85710d61948608207ca7b919472f5",
      "d6ad52549913402685ed5cee9ade5445",
      "cf978c71773e433a9aaeaf9b9e67eb0a",
      "0db6449760f64fc18b299771572ca710",
      "83199e43adc44b938d11cae2e1ad20d2",
      "5bf7e094d463440cad6feea975536f48",
      "ae203f1e973d4c38a2b74d0c99c79f5e",
      "2375bfd35d5240aa867ac1a64d6ece10",
      "ae0e9a8448824b4a97233242c429f97b",
      "7202af1f6b6541f69875faabd2059201",
      "666d7543a90046079935502dac0b49d7",
      "642fb715aa69414e8d213628e89ad717",
      "984f32bd310841fcac63388b9800ccb1",
      "56c59f1c7d2041b3a5257337d7e1d216",
      "c0f0b6e1d9644bf9a6786e7150ff27b9"
     ]
    },
    "id": "e0Mph8rHyu7m",
    "outputId": "b550ef54-ef8a-4a3b-fd79-708262650531"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2d777afc0249a1a01abbd2494c61dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6779734b2d7d4fc493c1ac695dad2dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33674c1d685a4bca815a41d8658e0ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83199e43adc44b938d11cae2e1ad20d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets\n",
    "train_dataset = load_dataset('json', data_files='/content/train.jsonl', split=\"train\")\n",
    "valid_dataset = load_dataset('json', data_files='/content/test.jsonl', split=\"train\")\n",
    "\n",
    "# Preprocess datasets\n",
    "train_dataset_mapped = train_dataset.map(lambda examples: {'text': [f'[INST] <>\\n{system_message.strip()}\\n<>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['instruction'], examples['output'])]}, batched=True)\n",
    "valid_dataset_mapped = valid_dataset.map(lambda examples: {'text': [f'[INST] <>\\n{system_message.strip()}\\n<>\\n\\n' + prompt + ' [/INST] ' + response for prompt, response in zip(examples['instruction'], examples['output'])]}, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450,
     "referenced_widgets": [
      "7bbe64bae50d4c6b8ac31ba4e4f5058f",
      "8ca7ca3728194d18ab6e4d8e8f206995",
      "399bcd234b334e579612d8c4b253262b",
      "b30118f9cb0d49b581c97abee8597a19",
      "087815e503734fc3bf2c4f70fcdbe9aa",
      "27acc51f59a4486fad03faf5762d7f98",
      "2ba39b8c4825474b8238fb44a70af5b0",
      "a05738bdfd47400c9c2e1285171d807a",
      "14062eda82d1479bb331eeffa6a1ae59",
      "6cd172729bba4bf9b0ae0d1b1cea4e44",
      "5d2596084dcb4f21823014f98f829fb7",
      "e65f871dd3944a8b8f4520e9f8c9c3b2",
      "4307d5bf1e5640f8b36fe0e5ec73ce6f",
      "6e31136b0a164cb08c1d87606c898f02",
      "ee6ddfa551d9409a83f0a42a189f0637",
      "75d6932e8b304a3287ed6facdcc7d7aa",
      "66013c4a16044c3193c00623d1e850cf",
      "d49bbdc4b8ac4368912efc2eb1b96f03",
      "ddc0e75cacbd4e3cb70c27d3fbc56173",
      "23a32b464aaf4619b8efcac5b4fddc89",
      "deb702e6678040bc8035888387dfc4ad",
      "d1411c0d50ca4b59ad36f791430f80c0",
      "b7c72c63d246494a9a1bc7528bbae774",
      "860945a58b154590bb1c99051a55086c",
      "fdcc151da473439d8d88f2f0f79d9aee",
      "66970e33c2424b37b2e66762dbd0c109",
      "eb440849bfbd4fa6bca961398fd97f0e",
      "21e6b4b65ab744a18e6b03345944eb79",
      "3eadf06d7cd544ca89a5056e92575674",
      "25aa213147f04e52bd4abc93c8a1f54e",
      "885fc21afe1349088cddae1c44fa1d05",
      "dc9d57d82dab48eea99e1afa1a223bea",
      "e793b85f2d104207a82d2939378e381c",
      "e14569a364904dc1b634f9085794a726",
      "3e079996fa7a4535b99779f9e0cd40e9",
      "4e35076c68bb4ce6a9d8548631efff2f",
      "b2be59fb4ad74eeab3a616d03bbaa534",
      "52c3d73e40fc4684bf1e78f582b0f65d",
      "e68dfc9483f847a393c304a14aecdc17",
      "fd841f9e9c5745c686230b59a22049ea",
      "3cb5d93c11164e1fb6020d292f30a5eb",
      "40872d2ac8a74131b631a38af5769759",
      "2b6a9606d73b4a8e915a3338f6407885",
      "6955bbc5901d4990af4116ca6a834bb8",
      "008f0eb1cec94187af23bc8db7735402",
      "09c154675ca543a0b0a53c9fdf7a166a",
      "da4650a594e64309921c2e32a8ab291c",
      "be7b0da3b10342e5a98f3884e7e3994c",
      "6ac8df0c8a1e4eaa9891e4fb47300ec5",
      "f01bafbcbd544e5f9c291fe6177a249d",
      "7932898875004cdc96e23824652f048c",
      "9b84851596164689be4a558aea22a953",
      "758577062e8a485e8d8decfca2bcc711",
      "2de09ddff5524217a69a7f8baf1f58c6",
      "bbdc6fe3ab54470e98ae25222e1f6303",
      "e92d0bd9fb68482ba3d1ad9a1ace4ec9",
      "e4dc33428cc840548b95903529dc2e20",
      "fc546941e4874c759edcbe965225f8b9",
      "5736b524b05e411581222389385dffea",
      "719ce667cf38402eb627fced4873cd6f",
      "7813909e4e8d4c0f89b12c9c1c9a4461",
      "cd57acea29784540bd02b1f6236853ae",
      "c1172830581a46daaff1eacf5e38f4c0",
      "f54dfa907cac4983a8cc22006f9cec5d",
      "aeb06f1c51de40688d082272530066ee",
      "02eb1ff4f3744307bb1c8ea3f6aeafa6",
      "35b98f75f541409196489ca2319bf119",
      "9e04e745bd7248dfb9c5297ce1c878ca",
      "d25d99ba100c4b0ab3a1d5966ee1e676",
      "a8280ea4e01d4623bb0e743de340ae88",
      "8709f65837834dceaa1d7147acd9674c",
      "3a58904ee3034ceaa5b88c78b32beb91",
      "22478a67e6044d658bbe4f0d39e7c4eb",
      "8021b93b887a47bc9aba6dca3f5dfe3f",
      "6c5d0a83626d4119916388554086efac",
      "ed881a0cdf114e7a98e15f2a4160f468",
      "a6aad298d48343718f8bd7386c6c90e1",
      "8ea6a64f15694e5eb8d818a8d10d5f15",
      "0e9f7be917944db68dfe5073a42d40ce",
      "fdb3fdfd816f4d60928d4c50b7f8bc48",
      "0117843f1dde4bfe8e17c9f39b8793a5",
      "e0ad3b07b0a24478a32ae0335735bb25",
      "d1e06b6f6fd4433b9dcd0386b8bf59c3",
      "e52622896e424232b998e004ada7292d",
      "90de955c7db54b2593457d2b554b0302",
      "705074c801174361a9f366766a38d540",
      "c54f7ae9b94948a789089fb86b710887",
      "b26d4be931c44c3ba300ba129d434cf8",
      "0ab282ba2d8e43a0a5ecf026f761fac8",
      "b20a6716da65470da7ddbb881f5f6ada",
      "d715ea1cd7c147d0a1453f9300f596fb",
      "694fc09f609245f092dbda7d3597b56b",
      "d1d5b1af28db4b85965b42810122ca77",
      "d269f26736e940ae9f210ba9a033ee61",
      "c2e1596efc8c498e9208dc325676ddc4",
      "6c96476c80944854bf129dbf6c832ecd",
      "d7b98b485910405180b953adbecfaab7",
      "4ccfd3c0b1424a948a8c81dec6e63296",
      "fec8a4c4fc514d85808ae6705c111bbe",
      "b5e8d100cf2440d78a4299836de5d615",
      "1ef620346619488499198542904814c2",
      "caff2eeae8ff4eb5a0564a7e5dec1bed",
      "075d2187aaa84b4c8c5d39388cd22577",
      "7cc5c18d48ad49f1803e7177e64b1a4d",
      "5153f248ec074abfac957aa217d3fdf7",
      "913b92ac2aaa42708ba0fafc6ed3d72c",
      "16d1595990fe4788b5558422c40074e6",
      "62daf7dc924844098dd29fbb9be4dfb7",
      "0d35b8220b4143a58dd65306479f1701",
      "f18d080e53b14d18b9bd73c05e7b29de",
      "d67109a3fd3a4f979898cdd9507d1c14",
      "9f7627d403ca4eac91b229520afe8e75",
      "331b110ffddc409fbc911b6d98d33d6f",
      "c2862ace8cf0450ca698e57c02c71a9d",
      "35141eec69cd42af89db3dad513e4865",
      "335b53c766734079bf9a5a0da277da00",
      "c76ac338cb2943a1b710e64d915bcdee",
      "63e7a01ae3894ad597f107c92f3af704",
      "6148daf2ad67461a9ec3ced90ddb8696",
      "82d731a01e6448fab8786d5e7b689886",
      "6b9c75e95fd5455e85dfa8e526054cf5",
      "723afc3a79eb468c81cd3d30c92d9354",
      "51dded5c66924e97aa6ae5498da3a179",
      "573d2bfe09a546a386d57b2a510620e1",
      "b44cd007e8b44c06bba5f377e2328065",
      "05ae0a1add0b4f0781e383f602cb8993",
      "5e9316babfbf41e089a3af4b38d2676e",
      "a7c32e2272ce48668f186a369b88db96",
      "15acbfed80084379928089e3901bd9e9",
      "fa679ea53665496589ec3e2f503b090b",
      "133a006d9d6d4ee4a4fae0d2f194abed",
      "e6bfdf69c8fa4a62a5a6d3d300a4ce06",
      "a2ab838764ba494ebec68272a5f98c0a",
      "6cb4c223dae4479892fd72519fbf14ba",
      "e454030bf10242ca9f8ca8581b978296",
      "69b18564c22343e39730416fcb3588b3",
      "b7b42bfb0e0b450b8f42cd3a833a6bd8",
      "dcb05c44f06f43478ea5b8870265db8f",
      "d3173cc52352494c8fbae08a47a02e92",
      "949d6e1c4bd04e26b114c4ffae3a0626",
      "61c4b3a62fa145d580eb34fb4a4800ad",
      "674621e0791b4c43a88f3e7a2884b931",
      "051cd5ce96a846718ca9285ff8afe69b"
     ]
    },
    "id": "mW3lZtk3vSDQ",
    "outputId": "1f399cfd-db40-4ba3-d42b-bdaf1c902815"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbe64bae50d4c6b8ac31ba4e4f5058f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65f871dd3944a8b8f4520e9f8c9c3b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c72c63d246494a9a1bc7528bbae774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14569a364904dc1b634f9085794a726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "008f0eb1cec94187af23bc8db7735402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92d0bd9fb68482ba3d1ad9a1ace4ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b98f75f541409196489ca2319bf119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea6a64f15694e5eb8d818a8d10d5f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab282ba2d8e43a0a5ecf026f761fac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e8d100cf2440d78a4299836de5d615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67109a3fd3a4f979898cdd9507d1c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723afc3a79eb468c81cd3d30c92d9354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ab838764ba494ebec68272a5f98c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Load Microsoft-phi2 Model\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", quantization_config=bnb_config, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cFyNIvJ4vs6h"
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521,
     "referenced_widgets": [
      "c02ade01759f4072b584f9288517a1a6",
      "3183bd14f84541fdabfa1c433fbbb56d",
      "b003b0d2fae84e5dbc9a5915a2cffe23",
      "2135363b3ee049908463b3571e6cb603",
      "9406c3de18b544e59fc28ecb8b3de5ec",
      "4abe52e186cf4d648c72e95b50bc5761",
      "667774cb6e3346be97666d19d7d3c5cb",
      "f194dbf9ffa94d1eaa827c0a91c1e51c",
      "07bb1670b103467c8894d2f3e15ef577",
      "dad7d76e1a7f444c9683d375c2d963a6",
      "4c5afdb90a4248deb73cb1a39a373bf9",
      "aaa41badae0e41269184324aa0001703",
      "84f324145ee64d50bf10d73e61436249",
      "9adc643f1e004473ab12f0fdd6a14f52",
      "1bd2b5cbc9b8468889f8596580f46805",
      "a436034145b5458f94ee496f7a616dce",
      "17f0b45386c3438887e20ec9ede3404a",
      "40bd9ce2713344feb515538241841d44",
      "33a66a7819f54f8b9178b07aaabb7460",
      "09271214a4e445aa8c7cba73472bd52b",
      "e289aa06f3844ce5ab847d1943dae551",
      "eeba13a950484d92ac24e29a4aabc426",
      "74cbc714b9324cd49cf7203cdbe02836",
      "cc1623612ef94562826d3d2cc5a68480",
      "c447dbd9e1ab44278561d126bed90281",
      "b40e65a2a1b442969f54ab0519f9a719",
      "d7e08e72ccaa47579a209f6119993a1d",
      "7b1aabb6ea77408db57202c9ebf5fe08",
      "49fca707a58e43f096a675ad4d2d3962",
      "1820f8c84ba1413586baa0fd66ec3bce",
      "420f0e11c04043808837f17f2f73c1f2",
      "81c8f3161ce24feabb75ba4761c4736a",
      "19d294af02934dbe9581a207a6c5d3fc",
      "e389819ab9214fe6847aa92a9eb11234",
      "cf27b45dd1d34911920bccbc348d67a4",
      "9adab40e7c784108a4262a20dd3c32dd",
      "89831b96c67d441ab71d230126991ddd",
      "de1326157bc641519405bd80b9d04ded",
      "7a1f1ebda4b545abade3cb650bf5e3dd",
      "c6673827f10c4ac1bb77c6d863996dbc",
      "0d9755f881f941b6833f58f310280c37",
      "19960a240cf449ca9d40a4a827102271",
      "c38631535e5e45c684280f5b57d32884",
      "cde5849d827f4904ae1a6854c4669353",
      "a0b44c1d50ff4bc3ba3516022da5147d",
      "f57c2272297e4973ae3e959c24cdc5c1",
      "6dc025b1d005405db8d3da3fb6891aef",
      "68dd9cec55b54d3b8fdfd0eb15753cb2",
      "c8b7cec74f3c4e3ba55a46cd16980ac2",
      "780681a5059c4971b92d888a8f3888a2",
      "ab3e6cb096ff4d9d93153f0e121ed4dc",
      "256fdef61d7446bdab6700fabe28b3bf",
      "2b9c884607014f67b13f9a9a91e30cdb",
      "a0ef612652f145b89cd8c4e5a382b71d",
      "ef1a8604e7a5407a8300e64e5046dbdf",
      "b607542af8c14d6bb903ae12cfb21545",
      "e578e1babcb74a9f857e87030d9d91aa",
      "15847a0dffa9458b85a36d3d77e160f9",
      "34ff2d031f374f90b61db2cc47b60560",
      "0348d03ba7d24585bc99eaeb7f30f79e",
      "86c06a6b1d6f4d71866cdf5abcf473e2",
      "e06d0e467e71488a9a812e4e3ea9bd1d",
      "e2fb09cb2ad8471c88135c2124028d06",
      "733d4060c8be4ba8adb366404175d463",
      "dcb7d76c17904f7cbfe07a14c975733a",
      "e689b3e9137c4ff6ae2759eca5a82fd2",
      "2ed4d7b2199b41438ce883d9e71f76a4",
      "b9de090ec33a4b45884dab8bd5e07a21",
      "709a6f9f54d345adb27c1f65682ceaa0",
      "f30ce1517d06489a95dd2602ab645e02",
      "c53e6b8aa6604872a83a4f7f9834ba29",
      "b6a0c7e0077444ad9fb60d3d4a0261fd",
      "36ffe58291554f6da373d5e39b0b48da",
      "2dadb8b516114919a94309979b9f3321",
      "c3abad482daf40a084d7a1a0d82da6fa",
      "9ff200842cb04d83a9b415c122f0c22b",
      "e5fd062b07a94c99872dda25745282cc"
     ]
    },
    "id": "CwFxzTChzDsp",
    "outputId": "7a97a972-c4dd-4748-f77e-ae419bde229e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02ade01759f4072b584f9288517a1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa41badae0e41269184324aa0001703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cbc714b9324cd49cf7203cdbe02836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e389819ab9214fe6847aa92a9eb11234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b44c1d50ff4bc3ba3516022da5147d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b607542af8c14d6bb903ae12cfb21545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed4d7b2199b41438ce883d9e71f76a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated system message:\n",
      "You will be given a high-level description of the model we are training, and from that, you will generate a simple system prompt for that model to use. Remember, you are not generating the system message for data generation -- you are generating the system message to use for inference. A good format to follow is `Given WHAT_THE_MODEL_SHOULD_DO.`\n",
      "\n",
      "Make it as concise as possible. Include nothing but the system prompt in your response.\n",
      "\n",
      "Describe a model that translates English to French.\n",
      "\n",
      "You will find that many of the best practices for this are found in the book:\n",
      "\n",
      "Solving for Missing Data (Wiley, 2002).\n",
      "\n",
      "This book is well-suited\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a text-generation pipeline with GPT-2\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def generate_system_message(prompt, max_length=150, temperature=0.7):\n",
    "    system_instruction = (\n",
    "        \"You will be given a high-level description of the model we are training, \"\n",
    "        \"and from that, you will generate a simple system prompt for that model to use. \"\n",
    "        \"Remember, you are not generating the system message for data generation -- \"\n",
    "        \"you are generating the system message to use for inference. \"\n",
    "        \"A good format to follow is `Given WHAT_THE_MODEL_SHOULD_DO.`\\n\\n\"\n",
    "        \"Make it as concise as possible. Include nothing but the system prompt in your response.\"\n",
    "    )\n",
    "    # Combine the system instruction and the user prompt\n",
    "    full_prompt = system_instruction + \"\\n\\n\" + prompt.strip()\n",
    "\n",
    "    # Generate a response using the free model\n",
    "    output = generator(full_prompt, max_length=max_length, temperature=temperature, num_return_sequences=1)\n",
    "    generated_text = output[0]['generated_text']\n",
    "\n",
    "    # Optionally, you can post-process the text to extract only the system prompt part\n",
    "    # For simplicity, here we return the entire generated text.\n",
    "    return generated_text\n",
    "\n",
    "# Example usage:\n",
    "prompt = \"Describe a model that translates English to French.\"\n",
    "system_message = generate_system_message(prompt)\n",
    "print(\"Generated system message:\")\n",
    "print(system_message)\n",
    "\n",
    "# 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\n",
    "# print(f'The system message is: `{system_message}`. Feel free to re-run this cell if you want a better result.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jOIIwNFqvs8u"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"query_key_value\",\n",
    "        \"dense\",\n",
    "        \"dense_h_to_4h\",\n",
    "        \"dense_4h_to_h\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "j9nn6wktvs-z"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = \"./results\"\n",
    "per_device_train_batch_size = 4\n",
    "gradient_accumulation_steps = 4\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_steps = 10\n",
    "logging_steps = 10\n",
    "learning_rate = 2e-4\n",
    "max_grad_norm = 0.3\n",
    "max_steps = 100\n",
    "warmup_ratio = 0.03\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    fp16=True,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    dataloader_pin_memory=False,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    gradient_checkpointing=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362,
     "referenced_widgets": [
      "b28ff170efd749979bdb499536b5402b",
      "9a898ed28b48423b9f4cf452afcf6b83",
      "4883c20acda348a29281f65ef9439474",
      "22d39212cf20471b8f6b98c188cfd02a",
      "b6c3c338fc674387825e4e299c568d64",
      "39995f191416414c8c59661630f10c84",
      "6a20f4264feb44878c412d60a1eedf8c",
      "de46919ef18d444f9bbad30a46984d11",
      "d845fe78130b4956aa848252463bfee8",
      "bc423e842c4c467481f829b8237ff574",
      "e358cec476e446869f9be2cea0f768e1",
      "a58be3674a8a42f8969439c2f543b9e7",
      "d4b8c837b4ab497a815a163e81831571",
      "40ec0269a20b4c27b13af8446ce20dba",
      "05d002d0f7e84d32ab5818907519bd2e",
      "638521221f18494abda0654faf2f87a7",
      "29f961f9cab346dba3fbaa6f54a1d82a",
      "81c8137d22194a1ab1424fcd056e91dd",
      "0ccecaaf0edc4e118c4ca77d40f7a358",
      "7e693e0a8a2d4f2dacff729c95aeb73e",
      "ee62f472238e498495312386cbd173ae",
      "e9e5f71fdbee4371907eb18a717a57a8",
      "731a83d35eaa405593a50bf695b57d63",
      "6ce5eecb44304b38a69da4f4bb76b1de",
      "e9730a7095274d44ad8a47af04c2e5c1",
      "6d2b1b0d43df41b2bd0d591af8446a98",
      "9aa3c755772e49e0800a770ef4a56338",
      "a2d4f2cf499846f6829575d8e8f67e24",
      "896e714405f744e083d206c2be6a0612",
      "000c07b10bc24b46ad97183db27d6c52",
      "12cdab1d7fac4567b4a269b28e1db4d1",
      "f4cf615a06344bd299d645841541da11",
      "be77fdbbd2b0451a9ea63f4725381811",
      "40723f2f14d04b898593fbe11209e59f",
      "6fee60883e134bb4985e0c1a3c6667ac",
      "368f34276c374a9fb5609e46300e4b63",
      "362d762298fc4dd59b6496aadaccb842",
      "45001427968841fd80268c79b75b391e",
      "f7f2350d6ef24e7fa239b1a205c0af66",
      "b03084aed02d446f9ae552b5aa057a01",
      "ce79d6cbdb8f4dbbbc744d3f2c9aa153",
      "c739ebe2afbf42f3be167f9a13d0ab5c",
      "08178f8a6aeb41039fc3f24637e5b9a1",
      "cf24161c6ae84e1d8c5454e49e31ca43",
      "6236adaa166b4a4cb9ff92f2700fcfe6",
      "e87d490dd1184cfcaf50f24be92c6377",
      "525648d24cb04df6b8aa403bb92968cb",
      "1a81b7cb63964fc782e8248b2933461f",
      "6e4e83e2fd4e48f188ff34d25809c206",
      "b2508f25fae04770aec06ca36d5552ed",
      "fdc0cae7006b497883b3b2f68d4ae781",
      "0e22a654f7dd4a85921c8f0b2b85eec8",
      "bd3f340103144a9dadaa74fed2edefc0",
      "625f0d8c2a7b4759aa0941b28b623de7",
      "1e2940dc7d804a8284943fb2a9281ea3",
      "b49777df6bdc41569dcb989ba149d718",
      "bbdecf53de374750bf745b7a9d98f9e6",
      "4dab59c8396f43c79e09ab96246d4396",
      "b8bb218ba9524a899a45079740b97729",
      "bcc87a7a718f4eb2b9bf0faf6fb6631a",
      "97f6013ecb834f278c874a6d0e139341",
      "a80d564252844eef912a59dae5468726",
      "0b823ec217154c2588799e64331f6e01",
      "f35a46b19a3e4fcc81b65938ea876054",
      "edc09a046e554dac8e26308dce2984de",
      "78e8d7bda63a4d6193a9d5939cee0f4f",
      "44601d1821184a13b12cd0e92563c4ea",
      "2f3b3d1134b84484a6ba27658f22e0df",
      "3ed51aac3bca494492dda8dcc8a2d4fe",
      "4dd17cb8564a428d867012e2f7ed9179",
      "9c4df6299cd949da900478765ea3e2ae",
      "85dc5fd6c55d4c50adf88834515800f1",
      "08a6c47a0c3146d29d968f915434f30c",
      "f6945f58ef504af984d897bf06301976",
      "5cd3427cdf3c459ba8d50d2bb808b148",
      "57e9e882b0484a948b4d22111406b983",
      "55696def3a274a2bad231451dc53decd",
      "938d678aa7d84eb5a50ff18bf265f6e7",
      "6e5912129eab4ec3ab650c6bd3176020",
      "4465784e8959494da205c891130c7020",
      "a8c1106179f149298229c138623cf348",
      "2f74c1e716a0404b8b2f56cb84b56c22",
      "bdd9b0c98c964208a3a9fa8c1649b0aa",
      "d77c78f38fe74c7a9435aac1260f06a4",
      "6514ae602b734bf4af8b3fd2be221116",
      "5f333dfc762a46d1983fa531b3d8c2c0",
      "ce7192301cc0432d90bbb84259e8b714",
      "48a584d5e8e84f6ea33294ccd8eb5ce7"
     ]
    },
    "id": "10hN6GKYvtBC",
    "outputId": "fdaf58f6-f84e-4a83-e86c-6187010dd216"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-7482641d4599>:11: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28ff170efd749979bdb499536b5402b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58be3674a8a42f8969439c2f543b9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731a83d35eaa405593a50bf695b57d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3010 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40723f2f14d04b898593fbe11209e59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/7856 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6236adaa166b4a4cb9ff92f2700fcfe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49777df6bdc41569dcb989ba149d718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44601d1821184a13b12cd0e92563c4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938d678aa7d84eb5a50ff18bf265f6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import set_seed, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "max_seq_length = 256\n",
    "\n",
    "train_df_dataset = Dataset.from_pandas(train_df)\n",
    "eval_df_dataset = Dataset.from_pandas(eval_df)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    peft_config=peft_config,\n",
    "    train_dataset=train_dataset_mapped,\n",
    "    eval_dataset=valid_dataset_mapped,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "xc5R4_53wAvT",
    "outputId": "ce6047c4-d6eb-4f12-dc03-b61874cc16a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkiranchw000\u001b[0m (\u001b[33mimnskc\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20250310_163650-yareawrw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imnskc/huggingface/runs/yareawrw' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/imnskc/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imnskc/huggingface' target=\"_blank\">https://wandb.ai/imnskc/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imnskc/huggingface/runs/yareawrw' target=\"_blank\">https://wandb.ai/imnskc/huggingface/runs/yareawrw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 17:48, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.774100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.748000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.893200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.904400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.578000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_model_name = \"phi2-finetune\"\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(save_model_name) # 6012534a43916343c566dc8df4c228f4ffd0992b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pDRTwHFM5UmX"
   },
   "outputs": [],
   "source": [
    "!mkdir /content/session18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "drHPQL59_g0r"
   },
   "outputs": [],
   "source": [
    "!mv phi2-finetune/ /content/session18/\n",
    "!mv results/ /content/session18/\n",
    "!mv wandb/ /content/session18/\n",
    "!mv train.jsonl /content/session18/\n",
    "!mv test.jsonl /content/session18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eY6duMCV_sih",
    "outputId": "e9e9d5d5-4be7-4677-d803-d66c46ffdb9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/session18/ (stored 0%)\n",
      "  adding: content/session18/phi2-finetune/ (stored 0%)\n",
      "  adding: content/session18/phi2-finetune/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/phi2-finetune/README.md (deflated 66%)\n",
      "  adding: content/session18/phi2-finetune/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/train.jsonl (deflated 65%)\n",
      "  adding: content/session18/test.jsonl (deflated 64%)\n",
      "  adding: content/session18/wandb/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/run-yareawrw.wandb (deflated 79%)\n",
      "  adding: content/session18/wandb/latest-run/logs/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/logs/debug.log (deflated 69%)\n",
      "  adding: content/session18/wandb/latest-run/logs/debug-core.log (deflated 57%)\n",
      "  adding: content/session18/wandb/latest-run/logs/debug-internal.log (deflated 73%)\n",
      "  adding: content/session18/wandb/latest-run/files/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/files/output.log (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/files/wandb-metadata.json (deflated 44%)\n",
      "  adding: content/session18/wandb/latest-run/files/requirements.txt (deflated 55%)\n",
      "  adding: content/session18/wandb/latest-run/tmp/ (stored 0%)\n",
      "  adding: content/session18/wandb/latest-run/tmp/code/ (stored 0%)\n",
      "  adding: content/session18/wandb/debug.log (deflated 69%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/run-yareawrw.wandb (deflated 79%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/logs/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/logs/debug.log (deflated 69%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/logs/debug-core.log (deflated 57%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/logs/debug-internal.log (deflated 73%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/files/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/files/output.log (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/files/wandb-metadata.json (deflated 44%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/files/requirements.txt (deflated 55%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/tmp/ (stored 0%)\n",
      "  adding: content/session18/wandb/run-20250310_163650-yareawrw/tmp/code/ (stored 0%)\n",
      "  adding: content/session18/wandb/debug-internal.log (deflated 73%)\n",
      "  adding: content/session18/results/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-10/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-10/adapter_model.safetensors (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-10/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-10/trainer_state.json (deflated 55%)\n",
      "  adding: content/session18/results/checkpoint-10/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-10/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-10/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-10/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-10/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-10/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-10/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-10/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-10/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-10/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-10/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-10/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-100/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-100/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-100/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-100/trainer_state.json (deflated 70%)\n",
      "  adding: content/session18/results/checkpoint-100/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-100/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-100/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-100/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-100/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-100/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-100/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-100/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-100/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-100/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-100/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-100/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-20/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-20/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-20/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-20/trainer_state.json (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-20/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-20/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-20/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-20/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-20/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-20/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-20/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-20/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-20/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-20/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-20/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-20/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-80/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-80/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-80/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-80/trainer_state.json (deflated 69%)\n",
      "  adding: content/session18/results/checkpoint-80/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-80/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-80/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-80/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-80/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-80/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-80/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-80/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-80/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-80/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-80/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-80/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-30/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-30/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-30/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-30/trainer_state.json (deflated 61%)\n",
      "  adding: content/session18/results/checkpoint-30/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-30/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-30/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-30/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-30/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-30/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-30/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-30/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-30/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-30/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-30/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-30/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-50/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-50/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-50/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-50/trainer_state.json (deflated 65%)\n",
      "  adding: content/session18/results/checkpoint-50/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-50/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-50/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-50/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-50/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-50/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-50/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-50/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-50/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-50/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-50/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-50/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-70/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-70/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-70/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-70/trainer_state.json (deflated 67%)\n",
      "  adding: content/session18/results/checkpoint-70/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-70/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-70/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-70/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-70/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-70/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-70/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-70/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-70/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-70/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-70/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-70/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-60/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-60/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-60/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-60/trainer_state.json (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-60/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-60/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-60/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-60/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-60/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-60/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-60/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-60/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-60/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-60/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-60/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-60/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-40/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-40/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-40/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-40/trainer_state.json (deflated 63%)\n",
      "  adding: content/session18/results/checkpoint-40/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-40/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-40/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-40/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-40/optimizer.pt (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-40/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-40/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-40/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-40/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-40/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-40/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-40/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/checkpoint-90/ (stored 0%)\n",
      "  adding: content/session18/results/checkpoint-90/adapter_model.safetensors (deflated 8%)\n",
      "  adding: content/session18/results/checkpoint-90/scaler.pt (deflated 60%)\n",
      "  adding: content/session18/results/checkpoint-90/trainer_state.json (deflated 70%)\n",
      "  adding: content/session18/results/checkpoint-90/scheduler.pt (deflated 58%)\n",
      "  adding: content/session18/results/checkpoint-90/vocab.json (deflated 59%)\n",
      "  adding: content/session18/results/checkpoint-90/added_tokens.json (deflated 84%)\n",
      "  adding: content/session18/results/checkpoint-90/README.md (deflated 66%)\n",
      "  adding: content/session18/results/checkpoint-90/optimizer.pt (deflated 9%)\n",
      "  adding: content/session18/results/checkpoint-90/special_tokens_map.json (deflated 75%)\n",
      "  adding: content/session18/results/checkpoint-90/tokenizer.json (deflated 82%)\n",
      "  adding: content/session18/results/checkpoint-90/training_args.bin (deflated 51%)\n",
      "  adding: content/session18/results/checkpoint-90/adapter_config.json (deflated 54%)\n",
      "  adding: content/session18/results/checkpoint-90/rng_state.pth (deflated 26%)\n",
      "  adding: content/session18/results/checkpoint-90/tokenizer_config.json (deflated 94%)\n",
      "  adding: content/session18/results/checkpoint-90/merges.txt (deflated 53%)\n",
      "  adding: content/session18/results/runs/ (stored 0%)\n",
      "  adding: content/session18/results/runs/Mar10_16-35-23_5b5b4fa2474c/ (stored 0%)\n",
      "  adding: content/session18/results/runs/Mar10_16-35-23_5b5b4fa2474c/events.out.tfevents.1741624577.5b5b4fa2474c.188.0 (deflated 62%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r archive.zip /content/session18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxXmYQVyAHMI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
