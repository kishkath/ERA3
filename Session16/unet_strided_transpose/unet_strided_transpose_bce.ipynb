{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10886118,"sourceType":"datasetVersion","datasetId":6764607}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/kishkath/ERA3.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-01T14:09:30.035160Z","iopub.execute_input":"2025-03-01T14:09:30.035359Z","iopub.status.idle":"2025-03-01T14:09:32.350273Z","shell.execute_reply.started":"2025-03-01T14:09:30.035338Z","shell.execute_reply":"2025-03-01T14:09:32.349236Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'ERA3'...\nremote: Enumerating objects: 857, done.\u001b[K\nremote: Counting objects: 100% (151/151), done.\u001b[K\nremote: Compressing objects: 100% (138/138), done.\u001b[K\nremote: Total 857 (delta 90), reused 18 (delta 6), pack-reused 706 (from 1)\u001b[K\nReceiving objects: 100% (857/857), 9.60 MiB | 11.16 MiB/s, done.\nResolving deltas: 100% (412/412), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/working/ERA3/Session16/\")\n\nprint(\">>> current working directory: \", os.getcwd())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T14:09:32.351436Z","iopub.execute_input":"2025-03-01T14:09:32.351846Z","iopub.status.idle":"2025-03-01T14:09:32.357284Z","shell.execute_reply.started":"2025-03-01T14:09:32.351814Z","shell.execute_reply":"2025-03-01T14:09:32.356396Z"}},"outputs":[{"name":"stdout","text":">>> current working directory:  /kaggle/working/ERA3/Session16\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from types import SimpleNamespace\nfrom main import main\n\nargs = SimpleNamespace(\n    data_root=\"./data/oxford-iiit-pet\" ,         # Dataset will be downloaded here.\n    epochs=10,                  # Use a small number of epochs for testing.\n    batch_size=32,\n    lr=1e-4,\n    model_type=\"strided_transpose\",\n    step_size=8,\n    gamma=0.1,\n    bce_weight=0.5,\n    plot_samples=12,\n    loss_type=\"bce\",\n    checkpoint_path=\"/kaggle/working/checkpoint.pth\",\n    infer_image=\"/kaggle/input/infernce/cat.jpg\"              # Provide a valid path to test inference, if desired.\n)\n\nmain(args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-01T14:09:32.358192Z","iopub.execute_input":"2025-03-01T14:09:32.358742Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"name":"stdout","text":"Dataset not found. Downloading Oxford-IIIT Pet dataset via torchvision...\nDownloading https://thor.robots.ox.ac.uk/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 792M/792M [00:52<00:00, 15.1MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\nDownloading https://thor.robots.ox.ac.uk/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 19.2M/19.2M [00:02<00:00, 7.32MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n[INFO] Using device: cuda\n[INFO] Loading dataset using CustomDataset...\nBefore Removing:  7390 7390\nAfter Removing:  7384 7384\n[INFO] Dataset ready: 5907 training samples, 1477 validation samples.\n[INFO] Strided as Encoder & Transpose Conv as Decoder\nStridedEncoder initialized successfully.\nDecoder (Transpose) initialized successfully.\nStridedUNetTranspose model initialized successfully.\n[INFO] strided_transpose model initialized.\n[INFO] Using loss function: bce\n[INFO] Optimizer and scheduler set.\n\n[INFO] Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 1: Avg Train Loss: 0.4262 | Train Accuracy: 80.60%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 1: Avg Val Loss: 0.3664 | Val Accuracy: 84.23%\n[INFO] Saved best model with loss 0.3664 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 1s\n\n[INFO] Epoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 2: Avg Train Loss: 0.3073 | Train Accuracy: 87.26%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 2: Avg Val Loss: 0.2870 | Val Accuracy: 88.35%\n[INFO] Saved best model with loss 0.2870 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 19s\n\n[INFO] Epoch 3/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 3: Avg Train Loss: 0.2660 | Train Accuracy: 89.10%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 3: Avg Val Loss: 0.2646 | Val Accuracy: 88.77%\n[INFO] Saved best model with loss 0.2646 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 20s\n\n[INFO] Epoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 4: Avg Train Loss: 0.2392 | Train Accuracy: 90.28%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 4: Avg Val Loss: 0.2480 | Val Accuracy: 89.83%\n[INFO] Saved best model with loss 0.2480 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 22s\n\n[INFO] Epoch 5/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 5: Avg Train Loss: 0.2182 | Train Accuracy: 91.22%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 5: Avg Val Loss: 0.2500 | Val Accuracy: 89.89%\n[INFO] Epoch completed in 6m 20s\n\n[INFO] Epoch 6/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 6: Avg Train Loss: 0.2041 | Train Accuracy: 91.80%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 6: Avg Val Loss: 0.2244 | Val Accuracy: 90.85%\n[INFO] Saved best model with loss 0.2244 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 20s\n\n[INFO] Epoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 7: Avg Train Loss: 0.1875 | Train Accuracy: 92.54%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 7: Avg Val Loss: 0.2180 | Val Accuracy: 91.14%\n[INFO] Saved best model with loss 0.2180 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 20s\n\n[INFO] Epoch 8/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 8: Avg Train Loss: 0.1642 | Train Accuracy: 93.55%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 8: Avg Val Loss: 0.2126 | Val Accuracy: 91.50%\n[INFO] Saved best model with loss 0.2126 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 22s\n\n[INFO] Epoch 9/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 9: Avg Train Loss: 0.1250 | Train Accuracy: 95.30%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 9: Avg Val Loss: 0.1926 | Val Accuracy: 92.49%\n[INFO] Saved best model with loss 0.1926 to /kaggle/working/checkpoint.pth\n[INFO] Epoch completed in 6m 20s\n\n[INFO] Epoch 10/10\n","output_type":"stream"},{"name":"stderr","text":"                                                                                 \r","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 10: Avg Train Loss: 0.1123 | Train Accuracy: 95.85%\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/ERA3/Session16/main.py:144: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(args.checkpoint_path, map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"[INFO] Epoch 10: Avg Val Loss: 0.1955 | Val Accuracy: 92.48%\n[INFO] Epoch completed in 6m 20s\n[INFO] Training complete.\n[ERROR] Plotting samples failed: 'types.SimpleNamespace' object has no attribute 'plot_mode'\n[INFO] Running inference on: /kaggle/input/infernce/cat.jpg\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}